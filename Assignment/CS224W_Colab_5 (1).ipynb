{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS224W_Colab_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this Colab we will experiment on scaling up GNNs using PyTorch Geometric, DeepSNAP and NetworkX. As we have **canceled** the Colab 5 assignment, this notebook will be a tutorial and you do not need to submit it on Gradescope.\n",
        "\n",
        "At first, we will use PyTorch Geometric `NeighborSampler` to scale up the training and testing on OGB `arxiv` dataset.\n",
        "\n",
        "Then, using the DeepSNAP and NetworkX, we will implement a simplified version of `NeighborSampler` and run experiments with different smapling ratios on the Cora graph.\n",
        "\n",
        "At last, we will partition the Cora graph into clusters by using different partition algorithms and then train the models in the way of vanilla Cluster-GCN.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "You might need to use GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbz9B-erPgZC",
        "outputId": "bade58f8-3052-4c2f-f242-f0109b1108d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul 24 08:06:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_m9l6OYCQZP"
      },
      "source": [
        "# !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "# !pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "# !pip install -q torch-geometric\n",
        "# !pip install -q ogb\n",
        "# !pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
        "!pip install -q torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op8lTRfQPjz7",
        "outputId": "7aaeacc6-10d8-4b54-dc5f-ce12fa924134"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 33.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 23.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stanford DeepSNAP 설치\n",
        "\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAL9WTX2Pj2S",
        "outputId": "05eb00f7-77f2-452e-e3d7-4640dccc5965"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UP-gAMqPtWi",
        "outputId": "4d94c4a3-5003-4ff5-b91f-deed29f6ce95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 71 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfgbfTjCRD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f57e285b-25ed-4786-9a2d-60c4cd122524"
      },
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxkYLgxAOxz7"
      },
      "source": [
        "# 1 PyTorch Geometric Neighbor Sampling\n",
        "\n",
        "Neighbor Sampling, originally proposed in **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)), is a representative method to scale up GNNs. As what we have learned in lecture, only a K-hop neighborhood nodes will be loaded into GPU for each time training. To further reduce the cost, we can sample a subset of neighborhood nodes for GNNs to aggregate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kho6SHUVO1ny"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1WJLGKsOx_k"
      },
      "source": [
        "# import copy\n",
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# import torch_geometric.transforms as T\n",
        "\n",
        "# from torch_geometric.nn import SAGEConv\n",
        "# from torch_geometric.data import NeighborSampler\n",
        "# from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
      ],
      "metadata": {
        "id": "GuzQBPGSQG57"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqZWqRbO7km"
      },
      "source": [
        "## Neighbor Sampler\n",
        "\n",
        "PyTorch Geometric has implemented the Neighbor Sampling method as the [NeighborSampler](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.NeighborSampler) in `torch_geometric.data`. Following is an example that uses the Neighbor Sampling method on training the OGB `arxiv` dataset.\n",
        "\n",
        "If you are interested in memory-efficient aggregations, please refer to PyG's [Memory-Efficient Aggregations](https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWlyStlRO6_u"
      },
      "source": [
        "# dataset_name = 'ogbn-arxiv'\n",
        "# dataset = PygNodePropPredDataset(name=dataset_name,\n",
        "#                                  transform=T.ToSparseTensor())\n",
        "# data = dataset[0]\n",
        "# data.adj_t = data.adj_t.to_symmetric()\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# print('Device: {}'.format(device))\n",
        "\n",
        "# data = data.to(device)\n",
        "# split_idx = dataset.get_idx_split()\n",
        "# train_idx = split_idx['train'].to(device)\n",
        "\n",
        "# # Construct the training dataloader for training data\n",
        "# # Sample 10 neighbors for each node in the first layer and 5 for the second layer\n",
        "# train_loader = NeighborSampler(data.adj_t, node_idx=train_idx,\n",
        "#                                sizes=[10, 5], batch_size=4096,\n",
        "#                                shuffle=True, num_workers=2)\n",
        "\n",
        "# # Specify size as -1 to include all neighbors\n",
        "# all_loader = NeighborSampler(data.adj_t, node_idx=None, sizes=[-1],\n",
        "#                                   batch_size=4096, shuffle=False,\n",
        "#                                   num_workers=2)\n",
        "# evaluator = Evaluator(name='ogbn-arxiv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'ogbn-arxiv'\n",
        "\n",
        "dataset = PygNodePropPredDataset(name = dataset_name,\n",
        "                                 transform = T.ToSparseTensor())\n",
        "\n",
        "data = dataset[0]\n",
        "data.adj_t = data.adj_t.to_symmetric()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f'Device : {format(device)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNugIU-1QWxq",
        "outputId": "3afa2a86-72bb-43b4-c670-8d30a6a3412b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:03<00:00, 22.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10034.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 5857.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Device : {format(device)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYD-jvuGRKTw",
        "outputId": "d8de016c-386b-4285-a053-3b8d7aef9fa3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.to(device)\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train'].to(device)"
      ],
      "metadata": {
        "id": "i-XFH54ORqzh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgM5yTD6RyQv",
        "outputId": "1349d857-9c59-49a1-c907-7617e3cfd64a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=2315598])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(split_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdwyBNegRzXq",
        "outputId": "17b08702-57bf-4f3a-c8a9-17ef4c05b715"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]), 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]), 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x9cxNeER1-p",
        "outputId": "e6a9c6a3-9e8c-42a9-ea16-e61cd18edba1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([     0,      1,      2,  ..., 169145, 169148, 169251], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "ZZ1RFkW8R-xX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the training dataloader for training data\n",
        "# Sample 10 neighbors for each node in the first layer and 5 for the second layer\n",
        "\n",
        "train_loader = NeighborSampler(data.adj_t,\n",
        "                               node_idx = train_idx,\n",
        "                               sizes = [10, 5],\n",
        "                               batch_size = 4096,\n",
        "                               shuffle=True,\n",
        "                               num_workers=2)\n",
        "\n",
        "# Specify size as -1 to include all neighbors\n",
        "all_loader = NeighborSampler(data.adj_t,\n",
        "                             node_idx = None,\n",
        "                             sizes = [-1],\n",
        "                             batch_size = 4096,\n",
        "                             shuffle=False,\n",
        "                             num_workers=2)\n",
        "\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ],
      "metadata": {
        "id": "5A2w4gg7RMRh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3AFUp4nPRMUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjdkIcFpRYyl"
      },
      "source": [
        "## GNN Model\n",
        "\n",
        "After creating the `NeighborSampler`, we also need to modify the model to let it support the mini-batch training.\n",
        "\n",
        "The `forward` function will take the node feature `x` and a list of three-element tuples `adjs`. Each element in `adjs` contains following elements:\n",
        "* `edge_index`: The edge index tensor between source and destination nodes, which forms a bipartite grpah.\n",
        "* `e_id`: The indices of the edges in the original graph.\n",
        "* `size`: The shape of the bipartite graph, in (*number of source nodes*, *number of destination nodes*) format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRBJS_5qRWbu"
      },
      "source": [
        "# class SAGE(torch.nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "#                  dropout):\n",
        "#         super(SAGE, self).__init__()\n",
        "\n",
        "#         self.convs = torch.nn.ModuleList()\n",
        "#         self.bns = torch.nn.ModuleList()\n",
        "\n",
        "#         self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
        "#         self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "#         for i in range(num_layers - 2):\n",
        "#             self.convs.append(\n",
        "#                 SAGEConv(hidden_dim, hidden_dim))\n",
        "#             self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "#         self.convs.append(SAGEConv(hidden_dim, output_dim))\n",
        "\n",
        "#         self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "#         self.dropout = dropout\n",
        "\n",
        "#         self.num_layers = num_layers\n",
        "\n",
        "#     def reset_parameters(self):\n",
        "#         for conv in self.convs:\n",
        "#             conv.reset_parameters()\n",
        "#         for bn in self.bns:\n",
        "#             bn.reset_parameters()\n",
        "\n",
        "#     def forward(self, x, adjs, mode=\"batch\"):\n",
        "#         if mode == \"batch\":\n",
        "#             for i, (edge_index, _, size) in enumerate(adjs):\n",
        "#                 # Extract target node features\n",
        "#                 x_target = x[:size[1]]\n",
        "\n",
        "#                 # Update x for next layer reuse\n",
        "#                 x = self.convs[i]((x, x_target), edge_index)\n",
        "#                 if i != self.num_layers - 1:\n",
        "#                     x = self.bns[i](x)\n",
        "#                     x = F.relu(x)\n",
        "#                     x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "#         else:\n",
        "#             for i, conv in enumerate(self.convs):\n",
        "#                 x = conv(x, adjs)\n",
        "#                 if i != self.num_layers - 1:\n",
        "#                     x = self.bns[i](x)\n",
        "#                     x = F.relu(x)\n",
        "#                     x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "#         return self.softmax(x)\n",
        "    \n",
        "#     def inference(self, x_all, all_loader):\n",
        "#         # This function will be called in test\n",
        "#         for i in range(self.num_layers):\n",
        "#             xs = []\n",
        "#             for batch_size, n_id, adj in all_loader:\n",
        "#                 edge_index, _, size = adj.to(device)\n",
        "#                 x = x_all[n_id].to(device)\n",
        "#                 x_target = x[:size[1]]\n",
        "#                 x = self.convs[i]((x, x_target), edge_index)\n",
        "#                 if i != self.num_layers - 1:\n",
        "#                     x = self.bns[i](x)\n",
        "#                     x = F.relu(x)\n",
        "#                     x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "                \n",
        "#                 # Append the node embeddings to xs\n",
        "#                 xs.append(x.cpu())\n",
        "            \n",
        "#             # Concat all embeddings into one tensor\n",
        "#             x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "#         return x_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
        "    super(SAGE, self).__init__()\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.bns = torch.nn.ModuleList()\n",
        "\n",
        "    self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
        "    self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "    for i in range(num_layers - 2):\n",
        "      self.convs.append(\n",
        "          SAGEConv(hidden_dim, hidden_dim)\n",
        "      )\n",
        "\n",
        "      self.bns.append(\n",
        "          torch.nn.BatchNorm1d(hidden_dim)\n",
        "      )\n",
        "\n",
        "    self.convs.append(SAGEConv(hidden_dim, output_dim))\n",
        "    self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "    self.dropout = dropout\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "    for bn in self.bns:\n",
        "      bn.reset_parameters()\n",
        "\n",
        "  def forward(self, x, adjs, mode='batch'):\n",
        "    if mode == 'batch':\n",
        "      ##### adjs에서의 형태를 파악할 필요가 있다.\n",
        "      for i, (edge_index, _, size) in enumerate(adjs):\n",
        "        # Extract target node features\n",
        "        x_target = x[:size[1]]\n",
        "\n",
        "        # Update x for next layer reuse\n",
        "        x = self.convs[i]((x, x_target), edge_index)\n",
        "\n",
        "        if i != self.num_layers - 1:\n",
        "          x = self.bns[i](x)\n",
        "          x = F.relu(x)\n",
        "          x = F.dropout(x,\n",
        "                        p = self.dropout,\n",
        "                        training = self.training)\n",
        "          \n",
        "      else:\n",
        "        for i, conv in enumerate(self.convs):\n",
        "          x = conv(x, adjs)\n",
        "          if i != self.num_layers - 1:\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x,\n",
        "                          p = self.dropout,\n",
        "                          training = self.training)\n",
        "      \n",
        "      return self.softmax(x)\n",
        "\n",
        "  def inference(self, x_all, all_loader):\n",
        "    # This function will be called in test\n",
        "    for i in range(self.num_layers):\n",
        "      xs = []\n",
        "      for batch_size, n_id, adj in all_loader:\n",
        "        edge_index, _, size = adj.to(device)\n",
        "        x = x_all[n_id].to(device)\n",
        "        x_target = x[:size[1]]\n",
        "        x = self.convs[i]((x, x_target), edge_index)\n",
        "\n",
        "        if i != self.num_layers - 1:\n",
        "          x = self.bns[i](x)\n",
        "          x = F.relu(x)\n",
        "          x = F.dropout(x,\n",
        "                        p=self.dropout,\n",
        "                        training=self.training)\n",
        "          \n",
        "        # Append the node embeddings to xs\n",
        "        xs.append(x.cpu())\n",
        "      \n",
        "      # Concat all embeddings into one tensor\n",
        "      x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "    return x_all\n"
      ],
      "metadata": {
        "id": "NuUl64fMSrex"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "\n",
        "        self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "        for i in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                SAGEConv(hidden_dim, hidden_dim))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "        self.convs.append(SAGEConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs, mode=\"batch\"):\n",
        "        if mode == \"batch\":\n",
        "            for i, (edge_index, _, size) in enumerate(adjs):\n",
        "                # Extract target node features\n",
        "                x_target = x[:size[1]]\n",
        "\n",
        "                # Update x for next layer reuse\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = self.bns[i](x)\n",
        "                    x = F.relu(x)\n",
        "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        else:\n",
        "            for i, conv in enumerate(self.convs):\n",
        "                x = conv(x, adjs)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = self.bns[i](x)\n",
        "                    x = F.relu(x)\n",
        "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return self.softmax(x)\n",
        "    \n",
        "    def inference(self, x_all, all_loader):\n",
        "        # This function will be called in test\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in all_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = self.bns[i](x)\n",
        "                    x = F.relu(x)\n",
        "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "                \n",
        "                # Append the node embeddings to xs\n",
        "                xs.append(x.cpu())\n",
        "            \n",
        "            # Concat all embeddings into one tensor\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        return x_all"
      ],
      "metadata": {
        "id": "erb_Vea7SrhW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cfm7K3wRqqY"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Now lets implement the training and testing functions.\n",
        "\n",
        "In both training and testing, we need to sample batch from the dataloader.\n",
        "\n",
        "Each batch in the `NeighborSampler` dataloader holds three elements:\n",
        "* `batch_size`: The batch size specified in the dataloader.\n",
        "* `n_id`: All nodes (in index format) used in the adjacency matrices.\n",
        "* `adjs`: The three-element tuples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JN0-_QCRn8N"
      },
      "source": [
        "# def train(model, data, train_loader, train_idx, optimizer, loss_fn, mode=\"batch\"):\n",
        "#     model.train()\n",
        "\n",
        "#     total_loss = 0\n",
        "#     if mode == \"batch\":\n",
        "#         for batch_size, n_id, adjs in train_loader:\n",
        "#             # Move all adj sparse tensors to GPU\n",
        "#             adjs = [adj.to(device) for adj in adjs]\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             # Index on the node features\n",
        "#             out = model(data.x[n_id], adjs)\n",
        "#             train_label = data.y[n_id[:batch_size]].squeeze(-1)\n",
        "#             loss = loss_fn(out, train_label)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss.item()\n",
        "#     else:\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(data.x, data.adj_t, mode=mode)[train_idx]\n",
        "#         train_label = data.y.squeeze(1)[train_idx]\n",
        "#         loss = loss_fn(out, train_label)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss = loss.item()\n",
        "\n",
        "#     return total_loss\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def test(model, data, all_loader, split_idx, evaluator, mode=\"batch\"):\n",
        "#     model.eval()\n",
        "\n",
        "#     if mode == \"batch\":\n",
        "#         out = model.inference(data.x, all_loader)\n",
        "#     else:\n",
        "#         out = model(data.x, data.adj_t, mode=\"all\")\n",
        "\n",
        "#     y_true = data.y.cpu()\n",
        "#     y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "#     train_acc = evaluator.eval({\n",
        "#         'y_true': y_true[split_idx['train']],\n",
        "#         'y_pred': y_pred[split_idx['train']],\n",
        "#     })['acc']\n",
        "#     valid_acc = evaluator.eval({\n",
        "#         'y_true': y_true[split_idx['valid']],\n",
        "#         'y_pred': y_pred[split_idx['valid']],\n",
        "#     })['acc']\n",
        "#     test_acc = evaluator.eval({\n",
        "#         'y_true': y_true[split_idx['test']],\n",
        "#         'y_pred': y_pred[split_idx['test']],\n",
        "#     })['acc']\n",
        "\n",
        "#     return train_acc, valid_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, train_loader, train_idx, optimizer, loss_fn, mode='batch'):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  if mode == 'batch':\n",
        "    for batch_size, n_id, adjs in train_loader:\n",
        "      # Move all adj sparse tensors to GPU\n",
        "      adjs = [adj.to(device) for adj in adjs]\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Index on the node features\n",
        "      out = model(data.x[n_id], adjs)\n",
        "      train_label = data.y[n_id[:batch_size]].squeeze(-1)\n",
        "      loss = loss_fn(out, train_label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "  else:\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t, mode=mode)[train_idx]\n",
        "    train_label = data.y.squeeze(1)[train_idx]\n",
        "    loss = loss_fn(out, train_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss = loss.item()\n",
        "\n",
        "  return total_loss  "
      ],
      "metadata": {
        "id": "DVckhVs8V2XO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data, all_loader, split_idx, evaluator, mode='batch'):\n",
        "  model.eval()\n",
        "\n",
        "  if mode == 'batch':\n",
        "    out = model.inference(data.x, all_loader)\n",
        "  else:\n",
        "    out = model(data.x, data.adj_t, mode='all')\n",
        "  \n",
        "  y_true = data.y.cpu()\n",
        "  y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "  train_acc = evaluator.eval({\n",
        "      'y_true': y_true[split_idx['train']],\n",
        "      'y_pred': y_pred[split_idx['train']]\n",
        "  })['acc']\n",
        "\n",
        "  valid_acc = evaluator.eval({\n",
        "      'y_true': y_true[split_idx['valid']],\n",
        "      'y_pred': y_pred[split_idx['valid']]\n",
        "  })['acc']\n",
        "\n",
        "  test_acc = evaluator.eval({\n",
        "      'y_true': y_true[split_idx['test']],\n",
        "      'y_pred': y_pred[split_idx['test']]\n",
        "  })['acc']\n",
        "\n",
        "  return train_acc, valid_acc, test_acc"
      ],
      "metadata": {
        "id": "8dtrPpwwXV3Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z0_nx2lnXV5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiehZ8OiR2q9"
      },
      "source": [
        "## Mini-batch Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFaI2eCARy0v"
      },
      "source": [
        "# args = {\n",
        "#     'device': device,\n",
        "#     'num_layers': 2,\n",
        "#     'hidden_dim': 128,\n",
        "#     'dropout': 0.5,\n",
        "#     'lr': 0.01,\n",
        "#     'epochs': 100,\n",
        "# }\n",
        "\n",
        "# batch_model = SAGE(data.num_features, args['hidden_dim'],\n",
        "#             dataset.num_classes, args['num_layers'],\n",
        "#             args['dropout']).to(device)\n",
        "# batch_model.reset_parameters()\n",
        "\n",
        "# optimizer = torch.optim.Adam(batch_model.parameters(), lr=args['lr'])\n",
        "# loss_fn = F.nll_loss\n",
        "\n",
        "# best_batch_model = None\n",
        "# best_valid_acc = 0\n",
        "\n",
        "# batch_results = []\n",
        "\n",
        "# for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "#     loss = train(batch_model, data, train_loader, train_idx, optimizer, loss_fn, mode=\"batch\")\n",
        "#     result = test(batch_model, data, all_loader, split_idx, evaluator, mode=\"batch\")\n",
        "#     batch_results.append(result)\n",
        "#     train_acc, valid_acc, test_acc = result\n",
        "#     if valid_acc > best_valid_acc:\n",
        "#         best_valid_acc = valid_acc\n",
        "#         best_batch_model = copy.deepcopy(batch_model)\n",
        "#     print(f'Epoch: {epoch:02d}, '\n",
        "#           f'Loss: {loss:.4f}, '\n",
        "#           f'Train: {100 * train_acc:.2f}%, '\n",
        "#           f'Valid: {100 * valid_acc:.2f}% '\n",
        "#           f'Test: {100 * test_acc:.2f}%')\n",
        "# best_result = test(best_batch_model, data, all_loader, split_idx, evaluator, mode=\"batch\")\n",
        "# train_acc, valid_acc, test_acc = best_result\n",
        "# print(f'Best model: '\n",
        "#       f'Train: {100 * train_acc:.2f}%, '\n",
        "#       f'Valid: {100 * valid_acc:.2f}% '\n",
        "#       f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 2,\n",
        "    'hidden_dim': 128,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 100,\n",
        "}"
      ],
      "metadata": {
        "id": "rtUQ_8UGX-P5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_model = SAGE(data.num_features,\n",
        "                   args['hidden_dim'],\n",
        "                   dataset.num_classes,\n",
        "                   args['num_layers'],\n",
        "                   args['dropout']).to(device)\n",
        "\n",
        "batch_model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(batch_model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.nll_loss\n",
        "\n",
        "best_batch_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "batch_results = []"
      ],
      "metadata": {
        "id": "So0cpWZOYmiX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 1+args['epochs']):\n",
        "  loss = train(batch_model,\n",
        "               data,\n",
        "               train_loader,\n",
        "               train_idx,\n",
        "               optimizer,\n",
        "               loss_fn,\n",
        "               mode='batch')\n",
        "\n",
        "  result = test(batch_model,\n",
        "                data,\n",
        "                all_loader,\n",
        "                split_idx,\n",
        "                evaluator,\n",
        "                mode='batch')\n",
        "  \n",
        "  batch_results.append(result)\n",
        "\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "\n",
        "  if valid_acc > best_valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "    best_batch_model = copy.deepcopy(batch_model)\n",
        "  \n",
        "  print(f'Epoch : {epoch:02d}, '\n",
        "        f'Loss : {loss:.4f}, '\n",
        "        f'Train : {100 * train_acc:.2f}%, '\n",
        "        f'Valid : {100 * valid_acc:.2f}%, '\n",
        "        f'Test : {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgQi1Nx2Ymkn",
        "outputId": "3bd01913-36d0-4038-e256-85a652e7d676"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 01, Loss : 39.7689, Train : 62.01%, Valid : 63.23%, Test : 62.15%\n",
            "Epoch : 02, Loss : 28.4164, Train : 67.13%, Valid : 66.75%, Test : 65.54%\n",
            "Epoch : 03, Loss : 26.5013, Train : 69.08%, Valid : 68.33%, Test : 66.98%\n",
            "Epoch : 04, Loss : 25.6248, Train : 69.71%, Valid : 67.80%, Test : 65.77%\n",
            "Epoch : 05, Loss : 25.0764, Train : 70.29%, Valid : 69.31%, Test : 68.35%\n",
            "Epoch : 06, Loss : 24.5563, Train : 71.02%, Valid : 69.31%, Test : 68.41%\n",
            "Epoch : 07, Loss : 24.2164, Train : 71.55%, Valid : 69.71%, Test : 68.84%\n",
            "Epoch : 08, Loss : 23.9690, Train : 71.81%, Valid : 69.71%, Test : 68.84%\n",
            "Epoch : 09, Loss : 23.7970, Train : 72.33%, Valid : 69.67%, Test : 67.89%\n",
            "Epoch : 10, Loss : 23.5282, Train : 72.34%, Valid : 70.18%, Test : 69.53%\n",
            "Epoch : 11, Loss : 23.2783, Train : 72.64%, Valid : 70.37%, Test : 69.48%\n",
            "Epoch : 12, Loss : 23.2010, Train : 73.04%, Valid : 69.72%, Test : 68.45%\n",
            "Epoch : 13, Loss : 23.0373, Train : 73.18%, Valid : 69.49%, Test : 67.80%\n",
            "Epoch : 14, Loss : 22.9350, Train : 73.06%, Valid : 70.38%, Test : 69.54%\n",
            "Epoch : 15, Loss : 22.8930, Train : 73.47%, Valid : 69.78%, Test : 68.45%\n",
            "Epoch : 16, Loss : 22.7270, Train : 73.51%, Valid : 70.65%, Test : 69.65%\n",
            "Epoch : 17, Loss : 22.6045, Train : 73.64%, Valid : 69.71%, Test : 68.28%\n",
            "Epoch : 18, Loss : 22.4473, Train : 73.82%, Valid : 70.30%, Test : 69.12%\n",
            "Epoch : 19, Loss : 22.3650, Train : 73.72%, Valid : 70.55%, Test : 69.99%\n",
            "Epoch : 20, Loss : 22.2267, Train : 74.05%, Valid : 70.12%, Test : 69.00%\n",
            "Epoch : 21, Loss : 22.2231, Train : 74.03%, Valid : 70.20%, Test : 68.69%\n",
            "Epoch : 22, Loss : 22.0896, Train : 74.21%, Valid : 69.68%, Test : 67.78%\n",
            "Epoch : 23, Loss : 22.0585, Train : 74.35%, Valid : 70.83%, Test : 70.08%\n",
            "Epoch : 24, Loss : 22.0075, Train : 74.52%, Valid : 70.74%, Test : 69.95%\n",
            "Epoch : 25, Loss : 22.0099, Train : 74.24%, Valid : 70.34%, Test : 69.49%\n",
            "Epoch : 26, Loss : 21.9705, Train : 74.69%, Valid : 70.64%, Test : 69.00%\n",
            "Epoch : 27, Loss : 21.9496, Train : 74.52%, Valid : 70.80%, Test : 70.01%\n",
            "Epoch : 28, Loss : 21.8533, Train : 74.80%, Valid : 70.37%, Test : 69.17%\n",
            "Epoch : 29, Loss : 21.6587, Train : 74.95%, Valid : 70.82%, Test : 69.83%\n",
            "Epoch : 30, Loss : 21.5551, Train : 75.01%, Valid : 70.79%, Test : 69.89%\n",
            "Epoch : 31, Loss : 21.5631, Train : 74.96%, Valid : 70.10%, Test : 68.48%\n",
            "Epoch : 32, Loss : 21.5295, Train : 74.82%, Valid : 70.39%, Test : 69.29%\n",
            "Epoch : 33, Loss : 21.4656, Train : 75.30%, Valid : 70.68%, Test : 69.64%\n",
            "Epoch : 34, Loss : 21.5043, Train : 75.40%, Valid : 70.54%, Test : 68.69%\n",
            "Epoch : 35, Loss : 21.4132, Train : 75.12%, Valid : 70.70%, Test : 69.87%\n",
            "Epoch : 36, Loss : 21.4541, Train : 75.51%, Valid : 70.60%, Test : 69.66%\n",
            "Epoch : 37, Loss : 21.3865, Train : 75.30%, Valid : 70.88%, Test : 70.21%\n",
            "Epoch : 38, Loss : 21.3577, Train : 75.58%, Valid : 71.18%, Test : 70.36%\n",
            "Epoch : 39, Loss : 21.3113, Train : 75.27%, Valid : 70.39%, Test : 69.03%\n",
            "Epoch : 40, Loss : 21.2117, Train : 75.44%, Valid : 70.51%, Test : 69.24%\n",
            "Epoch : 41, Loss : 21.1912, Train : 75.65%, Valid : 70.26%, Test : 68.86%\n",
            "Epoch : 42, Loss : 21.2244, Train : 75.60%, Valid : 70.60%, Test : 69.48%\n",
            "Epoch : 43, Loss : 21.2535, Train : 75.72%, Valid : 70.39%, Test : 69.06%\n",
            "Epoch : 44, Loss : 21.1187, Train : 75.84%, Valid : 70.13%, Test : 68.08%\n",
            "Epoch : 45, Loss : 21.0628, Train : 75.82%, Valid : 70.44%, Test : 69.25%\n",
            "Epoch : 46, Loss : 21.0792, Train : 75.74%, Valid : 70.70%, Test : 69.66%\n",
            "Epoch : 47, Loss : 21.0585, Train : 75.45%, Valid : 70.53%, Test : 69.27%\n",
            "Epoch : 48, Loss : 20.9773, Train : 76.08%, Valid : 70.98%, Test : 69.85%\n",
            "Epoch : 49, Loss : 20.9929, Train : 75.75%, Valid : 70.43%, Test : 69.55%\n",
            "Epoch : 50, Loss : 21.0219, Train : 76.24%, Valid : 70.89%, Test : 69.86%\n",
            "Epoch : 51, Loss : 20.9270, Train : 75.87%, Valid : 69.99%, Test : 68.28%\n",
            "Epoch : 52, Loss : 20.8406, Train : 76.08%, Valid : 70.28%, Test : 68.86%\n",
            "Epoch : 53, Loss : 20.8897, Train : 76.04%, Valid : 71.06%, Test : 70.53%\n",
            "Epoch : 54, Loss : 20.8368, Train : 76.04%, Valid : 70.62%, Test : 69.46%\n",
            "Epoch : 55, Loss : 20.7937, Train : 76.17%, Valid : 70.61%, Test : 69.21%\n",
            "Epoch : 56, Loss : 20.8453, Train : 76.36%, Valid : 70.84%, Test : 69.57%\n",
            "Epoch : 57, Loss : 20.7966, Train : 76.45%, Valid : 71.07%, Test : 69.86%\n",
            "Epoch : 58, Loss : 20.7125, Train : 76.27%, Valid : 71.01%, Test : 70.06%\n",
            "Epoch : 59, Loss : 20.6418, Train : 76.50%, Valid : 70.33%, Test : 68.92%\n",
            "Epoch : 60, Loss : 20.7759, Train : 76.39%, Valid : 70.86%, Test : 69.63%\n",
            "Epoch : 61, Loss : 20.7703, Train : 76.41%, Valid : 71.00%, Test : 70.34%\n",
            "Epoch : 62, Loss : 20.7668, Train : 76.42%, Valid : 70.45%, Test : 69.29%\n",
            "Epoch : 63, Loss : 20.6725, Train : 76.56%, Valid : 70.49%, Test : 69.14%\n",
            "Epoch : 64, Loss : 20.6352, Train : 76.61%, Valid : 70.84%, Test : 69.56%\n",
            "Epoch : 65, Loss : 20.5757, Train : 76.51%, Valid : 70.60%, Test : 69.26%\n",
            "Epoch : 66, Loss : 20.7058, Train : 76.70%, Valid : 70.84%, Test : 69.96%\n",
            "Epoch : 67, Loss : 20.6950, Train : 76.82%, Valid : 70.87%, Test : 70.13%\n",
            "Epoch : 68, Loss : 20.6091, Train : 76.41%, Valid : 70.33%, Test : 68.96%\n",
            "Epoch : 69, Loss : 20.4449, Train : 76.36%, Valid : 70.67%, Test : 69.46%\n",
            "Epoch : 70, Loss : 20.5886, Train : 76.76%, Valid : 70.50%, Test : 68.68%\n",
            "Epoch : 71, Loss : 20.5364, Train : 76.66%, Valid : 70.99%, Test : 69.97%\n",
            "Epoch : 72, Loss : 20.5208, Train : 76.69%, Valid : 70.57%, Test : 69.39%\n",
            "Epoch : 73, Loss : 20.3830, Train : 76.77%, Valid : 70.96%, Test : 70.00%\n",
            "Epoch : 74, Loss : 20.5043, Train : 76.42%, Valid : 70.55%, Test : 68.94%\n",
            "Epoch : 75, Loss : 20.4759, Train : 76.94%, Valid : 70.52%, Test : 69.00%\n",
            "Epoch : 76, Loss : 20.4884, Train : 76.74%, Valid : 70.43%, Test : 69.09%\n",
            "Epoch : 77, Loss : 20.5289, Train : 76.97%, Valid : 70.41%, Test : 68.65%\n",
            "Epoch : 78, Loss : 20.3871, Train : 76.87%, Valid : 70.79%, Test : 69.71%\n",
            "Epoch : 79, Loss : 20.4244, Train : 76.86%, Valid : 70.56%, Test : 69.35%\n",
            "Epoch : 80, Loss : 20.4728, Train : 77.08%, Valid : 71.01%, Test : 69.99%\n",
            "Epoch : 81, Loss : 20.4668, Train : 76.92%, Valid : 70.95%, Test : 70.03%\n",
            "Epoch : 82, Loss : 20.4858, Train : 77.00%, Valid : 70.99%, Test : 70.24%\n",
            "Epoch : 83, Loss : 20.4057, Train : 76.90%, Valid : 70.87%, Test : 70.01%\n",
            "Epoch : 84, Loss : 20.3335, Train : 77.13%, Valid : 70.79%, Test : 69.76%\n",
            "Epoch : 85, Loss : 20.3144, Train : 76.97%, Valid : 70.39%, Test : 68.66%\n",
            "Epoch : 86, Loss : 20.4724, Train : 76.83%, Valid : 70.84%, Test : 70.03%\n",
            "Epoch : 87, Loss : 20.3401, Train : 77.19%, Valid : 70.69%, Test : 69.25%\n",
            "Epoch : 88, Loss : 20.2918, Train : 77.16%, Valid : 70.90%, Test : 70.28%\n",
            "Epoch : 89, Loss : 20.2880, Train : 77.17%, Valid : 70.54%, Test : 68.95%\n",
            "Epoch : 90, Loss : 20.3513, Train : 76.98%, Valid : 70.80%, Test : 69.72%\n",
            "Epoch : 91, Loss : 20.2283, Train : 77.03%, Valid : 70.45%, Test : 69.29%\n",
            "Epoch : 92, Loss : 20.1769, Train : 77.10%, Valid : 70.65%, Test : 69.48%\n",
            "Epoch : 93, Loss : 20.2782, Train : 76.99%, Valid : 70.85%, Test : 69.68%\n",
            "Epoch : 94, Loss : 20.2594, Train : 77.23%, Valid : 71.09%, Test : 70.60%\n",
            "Epoch : 95, Loss : 20.2371, Train : 77.33%, Valid : 70.81%, Test : 69.53%\n",
            "Epoch : 96, Loss : 20.1946, Train : 77.26%, Valid : 70.76%, Test : 69.60%\n",
            "Epoch : 97, Loss : 20.1690, Train : 77.33%, Valid : 70.68%, Test : 69.10%\n",
            "Epoch : 98, Loss : 20.2104, Train : 77.28%, Valid : 70.28%, Test : 68.68%\n",
            "Epoch : 99, Loss : 20.2639, Train : 77.43%, Valid : 70.75%, Test : 69.57%\n",
            "Epoch : 100, Loss : 20.1841, Train : 77.19%, Valid : 70.64%, Test : 69.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = test(best_batch_model,\n",
        "                   data,\n",
        "                   all_loader,\n",
        "                   split_idx,\n",
        "                   evaluator,\n",
        "                   mode='batch')\n",
        "\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "\n",
        "print(f'Best model: '\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8TZLXMRY8tR",
        "outputId": "cec1a45c-81a3-422e-9ae8-34847416b97a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Train: 75.58%, Valid: 71.18% Test: 70.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pQlgtRwTZpIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OyqW-1pSMLW"
      },
      "source": [
        "## Full-batch Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU5eAviTSFMO"
      },
      "source": [
        "# # Use the same parameters for a full-batch training\n",
        "# args = {\n",
        "#     'device': device,\n",
        "#     'num_layers': 2,\n",
        "#     'hidden_dim': 128,\n",
        "#     'dropout': 0.5,\n",
        "#     'lr': 0.01,\n",
        "#     'epochs': 100,\n",
        "# }\n",
        "\n",
        "# all_model = SAGE(data.num_features, args['hidden_dim'],\n",
        "#             dataset.num_classes, args['num_layers'],\n",
        "#             args['dropout']).to(device)\n",
        "# all_model.reset_parameters()\n",
        "\n",
        "# optimizer = torch.optim.Adam(all_model.parameters(), lr=args['lr'])\n",
        "# loss_fn = F.nll_loss\n",
        "\n",
        "# best_all_model = None\n",
        "# best_valid_acc = 0\n",
        "\n",
        "# all_results = []\n",
        "\n",
        "# for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "#     loss = train(all_model, data, train_loader, train_idx, optimizer, loss_fn, mode=\"all\")\n",
        "#     result = test(all_model, data, all_loader, split_idx, evaluator, mode=\"all\")\n",
        "#     all_results.append(result)\n",
        "#     train_acc, valid_acc, test_acc = result\n",
        "#     if valid_acc > best_valid_acc:\n",
        "#         best_valid_acc = valid_acc\n",
        "#         best_all_model = copy.deepcopy(all_model)\n",
        "#     print(f'Epoch: {epoch:02d}, '\n",
        "#           f'Loss: {loss:.4f}, '\n",
        "#           f'Train: {100 * train_acc:.2f}%, '\n",
        "#           f'Valid: {100 * valid_acc:.2f}% '\n",
        "#           f'Test: {100 * test_acc:.2f}%')\n",
        "# best_result = test(best_all_model, data, all_loader, split_idx, evaluator, mode=\"all\")\n",
        "# train_acc, valid_acc, test_acc = best_result\n",
        "# print(f'Best model: '\n",
        "#       f'Train: {100 * train_acc:.2f}%, '\n",
        "#       f'Valid: {100 * valid_acc:.2f}% '\n",
        "#       f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full-batch Training\n",
        "\n",
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 2,\n",
        "    'hidden_dim': 128,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 100\n",
        "}"
      ],
      "metadata": {
        "id": "m8CMidbFcPFc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model = SAGE(data.num_features,\n",
        "                 args['hidden_dim'],\n",
        "                 dataset.num_classes,\n",
        "                 args['num_layers'],\n",
        "                 args['dropout']).to(device)\n",
        "\n",
        "all_model.reset_parameters()"
      ],
      "metadata": {
        "id": "k8xwKEvOcYE2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(all_model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.nll_loss"
      ],
      "metadata": {
        "id": "8WcoY8NlcYHF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_all_model = None\n",
        "best_valid_acc = 0\n",
        "all_results = []\n",
        "\n",
        "for epoch in range(1, 1+args['epochs']):\n",
        "  loss = train(all_model, data, train_loader, train_idx, optimizer, loss_fn, mode='all')\n",
        "  result = test(all_model, data, all_loader, split_idx, evaluator, mode='all')\n",
        "  all_results.append(result)\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "    best_all_model = copy.deepcopy(all_model)\n",
        "\n",
        "  print(f'Epoch : {epoch:02d}, '\n",
        "        f'Loss : {loss:.4f}, '\n",
        "        f'Train : {100 * train_acc:.2f}%, '\n",
        "        f'Valid : {100 * valid_acc:.2f}%, '\n",
        "        f'Test : {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj5j3Oj6ck0u",
        "outputId": "1f902b73-53df-41ed-cc26-ee7f7f3d579d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 01, Loss : 3.9672, Train : 31.43%, Valid : 32.89%, Test : 29.10%\n",
            "Epoch : 02, Loss : 2.5818, Train : 34.42%, Valid : 36.10%, Test : 33.89%\n",
            "Epoch : 03, Loss : 2.2303, Train : 36.53%, Valid : 42.94%, Test : 44.17%\n",
            "Epoch : 04, Loss : 2.0504, Train : 38.57%, Valid : 46.86%, Test : 49.70%\n",
            "Epoch : 05, Loss : 1.9124, Train : 43.01%, Valid : 50.18%, Test : 53.09%\n",
            "Epoch : 06, Loss : 1.8004, Train : 48.24%, Valid : 54.11%, Test : 56.32%\n",
            "Epoch : 07, Loss : 1.7105, Train : 51.56%, Valid : 56.30%, Test : 57.39%\n",
            "Epoch : 08, Loss : 1.6404, Train : 53.20%, Valid : 57.10%, Test : 57.06%\n",
            "Epoch : 09, Loss : 1.5817, Train : 54.38%, Valid : 57.73%, Test : 57.27%\n",
            "Epoch : 10, Loss : 1.5331, Train : 55.59%, Valid : 58.66%, Test : 58.27%\n",
            "Epoch : 11, Loss : 1.4928, Train : 56.27%, Valid : 59.48%, Test : 59.39%\n",
            "Epoch : 12, Loss : 1.4631, Train : 56.71%, Valid : 59.70%, Test : 60.18%\n",
            "Epoch : 13, Loss : 1.4396, Train : 57.23%, Valid : 60.08%, Test : 60.66%\n",
            "Epoch : 14, Loss : 1.4158, Train : 58.00%, Valid : 60.59%, Test : 60.96%\n",
            "Epoch : 15, Loss : 1.3960, Train : 58.93%, Valid : 61.18%, Test : 60.96%\n",
            "Epoch : 16, Loss : 1.3776, Train : 59.89%, Valid : 61.53%, Test : 60.99%\n",
            "Epoch : 17, Loss : 1.3596, Train : 60.77%, Valid : 62.21%, Test : 61.15%\n",
            "Epoch : 18, Loss : 1.3451, Train : 61.51%, Valid : 62.69%, Test : 61.54%\n",
            "Epoch : 19, Loss : 1.3298, Train : 62.11%, Valid : 63.39%, Test : 62.36%\n",
            "Epoch : 20, Loss : 1.3186, Train : 62.61%, Valid : 63.81%, Test : 63.07%\n",
            "Epoch : 21, Loss : 1.2971, Train : 63.04%, Valid : 64.15%, Test : 63.70%\n",
            "Epoch : 22, Loss : 1.2825, Train : 63.42%, Valid : 64.47%, Test : 64.11%\n",
            "Epoch : 23, Loss : 1.2738, Train : 63.84%, Valid : 64.71%, Test : 64.29%\n",
            "Epoch : 24, Loss : 1.2652, Train : 64.23%, Valid : 64.89%, Test : 64.45%\n",
            "Epoch : 25, Loss : 1.2514, Train : 64.63%, Valid : 65.12%, Test : 64.51%\n",
            "Epoch : 26, Loss : 1.2427, Train : 65.03%, Valid : 65.48%, Test : 64.54%\n",
            "Epoch : 27, Loss : 1.2346, Train : 65.28%, Valid : 65.72%, Test : 64.70%\n",
            "Epoch : 28, Loss : 1.2245, Train : 65.56%, Valid : 66.00%, Test : 64.91%\n",
            "Epoch : 29, Loss : 1.2141, Train : 65.88%, Valid : 66.21%, Test : 65.36%\n",
            "Epoch : 30, Loss : 1.2061, Train : 66.19%, Valid : 66.65%, Test : 65.77%\n",
            "Epoch : 31, Loss : 1.1975, Train : 66.47%, Valid : 66.87%, Test : 66.18%\n",
            "Epoch : 32, Loss : 1.1894, Train : 66.71%, Valid : 67.10%, Test : 66.54%\n",
            "Epoch : 33, Loss : 1.1844, Train : 66.99%, Valid : 67.23%, Test : 66.71%\n",
            "Epoch : 34, Loss : 1.1783, Train : 67.19%, Valid : 67.39%, Test : 66.76%\n",
            "Epoch : 35, Loss : 1.1714, Train : 67.37%, Valid : 67.55%, Test : 66.85%\n",
            "Epoch : 36, Loss : 1.1625, Train : 67.44%, Valid : 67.62%, Test : 66.87%\n",
            "Epoch : 37, Loss : 1.1590, Train : 67.56%, Valid : 67.66%, Test : 66.87%\n",
            "Epoch : 38, Loss : 1.1586, Train : 67.70%, Valid : 67.69%, Test : 66.98%\n",
            "Epoch : 39, Loss : 1.1533, Train : 67.80%, Valid : 67.76%, Test : 67.15%\n",
            "Epoch : 40, Loss : 1.1479, Train : 67.90%, Valid : 67.86%, Test : 67.19%\n",
            "Epoch : 41, Loss : 1.1410, Train : 68.07%, Valid : 67.92%, Test : 67.21%\n",
            "Epoch : 42, Loss : 1.1359, Train : 68.25%, Valid : 68.06%, Test : 67.19%\n",
            "Epoch : 43, Loss : 1.1339, Train : 68.36%, Valid : 68.16%, Test : 67.12%\n",
            "Epoch : 44, Loss : 1.1258, Train : 68.44%, Valid : 68.13%, Test : 67.10%\n",
            "Epoch : 45, Loss : 1.1226, Train : 68.54%, Valid : 68.07%, Test : 67.02%\n",
            "Epoch : 46, Loss : 1.1212, Train : 68.61%, Valid : 68.05%, Test : 67.08%\n",
            "Epoch : 47, Loss : 1.1185, Train : 68.77%, Valid : 68.21%, Test : 67.21%\n",
            "Epoch : 48, Loss : 1.1129, Train : 68.87%, Valid : 68.23%, Test : 67.35%\n",
            "Epoch : 49, Loss : 1.1103, Train : 68.97%, Valid : 68.31%, Test : 67.44%\n",
            "Epoch : 50, Loss : 1.1052, Train : 69.07%, Valid : 68.39%, Test : 67.49%\n",
            "Epoch : 51, Loss : 1.1028, Train : 69.13%, Valid : 68.46%, Test : 67.49%\n",
            "Epoch : 52, Loss : 1.0993, Train : 69.17%, Valid : 68.51%, Test : 67.48%\n",
            "Epoch : 53, Loss : 1.0989, Train : 69.23%, Valid : 68.54%, Test : 67.41%\n",
            "Epoch : 54, Loss : 1.0918, Train : 69.37%, Valid : 68.61%, Test : 67.49%\n",
            "Epoch : 55, Loss : 1.0850, Train : 69.42%, Valid : 68.67%, Test : 67.69%\n",
            "Epoch : 56, Loss : 1.0858, Train : 69.54%, Valid : 68.72%, Test : 67.91%\n",
            "Epoch : 57, Loss : 1.0794, Train : 69.63%, Valid : 68.78%, Test : 68.11%\n",
            "Epoch : 58, Loss : 1.0780, Train : 69.71%, Valid : 68.86%, Test : 68.20%\n",
            "Epoch : 59, Loss : 1.0755, Train : 69.82%, Valid : 68.94%, Test : 68.21%\n",
            "Epoch : 60, Loss : 1.0724, Train : 69.97%, Valid : 69.05%, Test : 68.18%\n",
            "Epoch : 61, Loss : 1.0690, Train : 70.06%, Valid : 69.06%, Test : 68.26%\n",
            "Epoch : 62, Loss : 1.0672, Train : 70.17%, Valid : 69.06%, Test : 68.21%\n",
            "Epoch : 63, Loss : 1.0625, Train : 70.23%, Valid : 69.05%, Test : 68.09%\n",
            "Epoch : 64, Loss : 1.0616, Train : 70.27%, Valid : 69.06%, Test : 68.01%\n",
            "Epoch : 65, Loss : 1.0603, Train : 70.31%, Valid : 69.10%, Test : 67.99%\n",
            "Epoch : 66, Loss : 1.0563, Train : 70.39%, Valid : 69.18%, Test : 67.94%\n",
            "Epoch : 67, Loss : 1.0555, Train : 70.43%, Valid : 69.13%, Test : 68.01%\n",
            "Epoch : 68, Loss : 1.0522, Train : 70.54%, Valid : 69.23%, Test : 68.07%\n",
            "Epoch : 69, Loss : 1.0492, Train : 70.67%, Valid : 69.27%, Test : 68.14%\n",
            "Epoch : 70, Loss : 1.0479, Train : 70.74%, Valid : 69.25%, Test : 68.13%\n",
            "Epoch : 71, Loss : 1.0443, Train : 70.78%, Valid : 69.25%, Test : 68.06%\n",
            "Epoch : 72, Loss : 1.0435, Train : 70.80%, Valid : 69.28%, Test : 68.03%\n",
            "Epoch : 73, Loss : 1.0431, Train : 70.83%, Valid : 69.25%, Test : 68.12%\n",
            "Epoch : 74, Loss : 1.0419, Train : 70.92%, Valid : 69.40%, Test : 68.37%\n",
            "Epoch : 75, Loss : 1.0368, Train : 70.96%, Valid : 69.41%, Test : 68.53%\n",
            "Epoch : 76, Loss : 1.0315, Train : 71.00%, Valid : 69.40%, Test : 68.59%\n",
            "Epoch : 77, Loss : 1.0336, Train : 71.04%, Valid : 69.41%, Test : 68.56%\n",
            "Epoch : 78, Loss : 1.0311, Train : 71.07%, Valid : 69.39%, Test : 68.62%\n",
            "Epoch : 79, Loss : 1.0270, Train : 71.15%, Valid : 69.46%, Test : 68.63%\n",
            "Epoch : 80, Loss : 1.0257, Train : 71.18%, Valid : 69.53%, Test : 68.56%\n",
            "Epoch : 81, Loss : 1.0265, Train : 71.23%, Valid : 69.50%, Test : 68.52%\n",
            "Epoch : 82, Loss : 1.0254, Train : 71.36%, Valid : 69.53%, Test : 68.63%\n",
            "Epoch : 83, Loss : 1.0224, Train : 71.39%, Valid : 69.67%, Test : 68.80%\n",
            "Epoch : 84, Loss : 1.0202, Train : 71.45%, Valid : 69.68%, Test : 68.83%\n",
            "Epoch : 85, Loss : 1.0198, Train : 71.48%, Valid : 69.71%, Test : 68.84%\n",
            "Epoch : 86, Loss : 1.0168, Train : 71.55%, Valid : 69.72%, Test : 68.78%\n",
            "Epoch : 87, Loss : 1.0130, Train : 71.60%, Valid : 69.68%, Test : 68.65%\n",
            "Epoch : 88, Loss : 1.0096, Train : 71.63%, Valid : 69.50%, Test : 68.46%\n",
            "Epoch : 89, Loss : 1.0107, Train : 71.68%, Valid : 69.44%, Test : 68.27%\n",
            "Epoch : 90, Loss : 1.0097, Train : 71.72%, Valid : 69.51%, Test : 68.34%\n",
            "Epoch : 91, Loss : 1.0087, Train : 71.78%, Valid : 69.64%, Test : 68.62%\n",
            "Epoch : 92, Loss : 1.0068, Train : 71.80%, Valid : 69.75%, Test : 68.81%\n",
            "Epoch : 93, Loss : 1.0036, Train : 71.86%, Valid : 69.94%, Test : 69.00%\n",
            "Epoch : 94, Loss : 1.0018, Train : 71.86%, Valid : 70.02%, Test : 69.15%\n",
            "Epoch : 95, Loss : 0.9977, Train : 71.86%, Valid : 70.08%, Test : 69.04%\n",
            "Epoch : 96, Loss : 1.0001, Train : 71.93%, Valid : 69.95%, Test : 68.91%\n",
            "Epoch : 97, Loss : 0.9989, Train : 72.01%, Valid : 70.01%, Test : 68.89%\n",
            "Epoch : 98, Loss : 0.9977, Train : 72.06%, Valid : 70.03%, Test : 69.08%\n",
            "Epoch : 99, Loss : 0.9934, Train : 72.06%, Valid : 70.12%, Test : 69.22%\n",
            "Epoch : 100, Loss : 0.9949, Train : 72.07%, Valid : 70.15%, Test : 69.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = test(best_all_model, data, all_loader, split_idx, evaluator, mode='all')\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "print(f'Best Model: '\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}%, '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1nwjl0Xck22",
        "outputId": "77859db0-01c6-4699-e2e3-c34e6257dc63"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: Train: 72.07%, Valid: 70.15%, Test: 69.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8VWFXnI8cPHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrECcOQQSZo1"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh_qvSG1SV63"
      },
      "source": [
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# batch_results = np.array(batch_results)\n",
        "# all_results = np.array(all_results)\n",
        "\n",
        "# x = np.arange(1, 101)\n",
        "\n",
        "# plt.figure(figsize=(9, 7))\n",
        "\n",
        "# plt.plot(x, batch_results[:, 1], label=\"Batch Validation\")\n",
        "# plt.plot(x, batch_results[:, 2], label=\"Batch Test\")\n",
        "# plt.plot(x, all_results[:, 1], label=\"All Validation\")\n",
        "# plt.plot(x, all_results[:, 2], label=\"All Test\")\n",
        "# plt.title('Model Accuracy')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "batch_results = np.array(batch_results)\n",
        "all_results = np.array(all_results)\n",
        "\n",
        "x = np.arange(1, 101)\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "\n",
        "plt.plot(x, batch_results[:, 1], label='Batch Validation')\n",
        "plt.plot(x, batch_results[:, 2], label='Batch Test')\n",
        "plt.plot(x, all_results[:, 1], label='All Validation')\n",
        "plt.plot(x, all_results[:, 2], label='All Test')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "BDwrqreAdv-h",
        "outputId": "4e02c143-eaeb-491e-bef7-0e0e083df679"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFb2OAvOSn_O"
      },
      "source": [
        "# 2 Neighbor Sampling with Different Ratios\n",
        "\n",
        "Now we will implement a simplified version of Neighbor Sampling by using DeepSNAP and NetworkX, and train models with different neighborhood sampling ratios.\n",
        "\n",
        "To make the experiments faster, we will use the Cora graph here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9U0F7bnSz9u"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUF4on-fSxcq"
      },
      "source": [
        "# import copy\n",
        "# import torch\n",
        "# import random\n",
        "# import numpy as np\n",
        "# import networkx as nx\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# from torch_geometric.nn import SAGEConv\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torch_geometric.datasets import Planetoid\n",
        "# from torch.nn import Sequential, Linear, ReLU\n",
        "# from deepsnap.dataset import GraphDataset\n",
        "# from deepsnap.graph import Graph\n",
        "\n",
        "# pyg_dataset = Planetoid('./tmp', \"Cora\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from deepsnap.graph import Graph"
      ],
      "metadata": {
        "id": "Uhs3RwXNeTqj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyg_dataset = Planetoid('./tmp', 'Cora')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snfbBKZ2euUa",
        "outputId": "c98c0710-a86a-46ce-b605-79653034910c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pyg_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp-dBJE0euWk",
        "outputId": "e71c49d2-db39-40b2-f0f9-9552adec83ee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cora()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw6k-KdFTEYw"
      },
      "source": [
        "## GNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUlNi2TS09i"
      },
      "source": [
        "# class GNN(torch.nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim, output_dim, args):\n",
        "#         super(GNN, self).__init__()\n",
        "#         self.dropout = args['dropout']\n",
        "#         self.num_layers = args['num_layers']\n",
        "\n",
        "#         self.convs = nn.ModuleList()\n",
        "#         self.bns = nn.ModuleList()\n",
        "\n",
        "#         self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
        "#         self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "#         for l in range(self.num_layers - 2):\n",
        "#             self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
        "#             self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "#         self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
        "\n",
        "#         self.post_mp = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "#     def forward(self, data, mode=\"batch\"):\n",
        "#         if mode == \"batch\":\n",
        "#             edge_indices, x = data\n",
        "#             for i in range(len(self.convs) - 1):\n",
        "#                 edge_index = edge_indices[i]\n",
        "#                 x = self.convs[i](x, edge_index)\n",
        "#                 x = self.bns[i](x)\n",
        "#                 x = F.relu(x)\n",
        "#                 x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "#             x = self.convs[-1](x, edge_indices[len(self.convs) - 1])\n",
        "#         else:\n",
        "#             x, edge_index = data.node_feature, data.edge_index\n",
        "#             for i in range(len(self.convs) - 1):\n",
        "#                 x = self.convs[i](x, edge_index)\n",
        "#                 x = self.bns[i](x)\n",
        "#                 x = F.relu(x)\n",
        "#                 x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "#             x = self.convs[-1](x, edge_index)\n",
        "#         x = self.post_mp(x)\n",
        "#         x = F.log_softmax(x, dim=1)\n",
        "#         return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, args):\n",
        "    super(GNN, self).__init__()\n",
        "    self.dropout = args['dropout']\n",
        "    self.num_layers = args['num_layers']\n",
        "\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.bns = nn.ModuleList()\n",
        "\n",
        "    self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
        "    self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "    for I in range(self.num_layers - 2):\n",
        "      self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
        "      self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "    self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n",
        "\n",
        "    self.post_mp = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, data, mode='batch'):\n",
        "    if mode == 'batch':\n",
        "      edge_indices, x = data\n",
        "      for i in range(len(self.convs) - 1):\n",
        "        edge_index = edge_indices[i]\n",
        "        x = self.convs[i](x, edge_index)\n",
        "        x = self.bns[i](x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "      x = self.convs[-1](x, edge_indices[len(self.convs) - 1])\n",
        "\n",
        "    else:\n",
        "      x, edge_index = data.node_feature, data.edge_index\n",
        "      \n",
        "      for i in range(len(self.convs) - 1):\n",
        "        x = self.convs[i](x, edge_index)\n",
        "        x = self.bns[i](x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "      x = self.convs[-1](x, edge_index)\n",
        "    \n",
        "    x = self.post_mp(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "XoHqbpP6e0jH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wKZ6boZhfiVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulp1A3evcJ-I"
      },
      "source": [
        "## Neighbor Sampling\n",
        "\n",
        "Here we implement functions that will sample neighbors by using DeepSNAP and NetworkX.\n",
        "\n",
        "Notice that node classification task on Cora is a semi-supervised classification task, here we keep all the labeled training nodes (140 nodes) by setting the last ratio to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI4qHkE4cQOh"
      },
      "source": [
        "# def sample_neighbors(nodes, G, ratio, all_nodes):\n",
        "#     # This fuction takes a set of nodes, a NetworkX graph G and neighbor sampling ratio.\n",
        "#     # It will return sampled neighbors (unioned with input nodes) and edges between \n",
        "#     neighbors = set()\n",
        "#     edges = []\n",
        "#     for node in nodes:\n",
        "#         neighbors_list = list(nx.neighbors(G, node))\n",
        "\n",
        "#         # We only sample the (ratio * number of neighbors) neighbors\n",
        "#         num = int(len(neighbors_list) * ratio)\n",
        "#         if num > 0:\n",
        "#             # Random shuffle the neighbors\n",
        "#             random.shuffle(neighbors_list)\n",
        "#             neighbors_list = neighbors_list[:num]\n",
        "#             for neighbor in neighbors_list:\n",
        "#                 # Add neighbors\n",
        "#                 neighbors.add(neighbor)\n",
        "#                 edges.append((neighbor, node))\n",
        "#     return neighbors, neighbors.union(all_nodes), edges\n",
        "\n",
        "# def nodes_to_tensor(nodes):\n",
        "#     # This function transform a set of nodes to node index tensor\n",
        "#     node_label_index = torch.tensor(list(nodes), dtype=torch.long)\n",
        "#     return node_label_index\n",
        "\n",
        "# def edges_to_tensor(edges):\n",
        "#     # This function transform a set of edges to edge index tensor\n",
        "#     edge_index = torch.tensor(list(edges), dtype=torch.long)\n",
        "#     edge_index = torch.cat([edge_index, torch.flip(edge_index, [1])], dim=0)\n",
        "#     edge_index = edge_index.permute(1, 0)\n",
        "#     return edge_index\n",
        "\n",
        "# def relable(nodes, labeled_nodes, edges_list):\n",
        "#     # Relable the nodes, labeled_nodes and edges_list\n",
        "#     relabled_edges_list = []\n",
        "#     sorted_nodes = sorted(nodes)\n",
        "#     node_mapping = {node : i for i, node in enumerate(sorted_nodes)}\n",
        "#     for orig_edges in edges_list:\n",
        "#         relabeled_edges = []\n",
        "#         for edge in orig_edges:\n",
        "#             relabeled_edges.append((node_mapping[edge[0]], node_mapping[edge[1]]))\n",
        "#         relabled_edges_list.append(relabeled_edges)\n",
        "#     relabeled_labeled_nodes = [node_mapping[node] for node in labeled_nodes]\n",
        "#     relabeled_nodes = [node_mapping[node] for node in nodes]\n",
        "#     return relabled_edges_list, relabeled_nodes, relabeled_labeled_nodes\n",
        "\n",
        "# def neighbor_sampling(graph, K=2, ratios=(0.1, 0.1, 0.1)):\n",
        "#     # This function takes a DeepSNAP graph, K the number of GNN layers, and neighbor \n",
        "#     # sampling ratios for each layer. This function returns relabeled node feature, \n",
        "#     # edge indices and node_label_index\n",
        "\n",
        "#     assert K + 1 == len(ratios)\n",
        "\n",
        "#     labeled_nodes = graph.node_label_index.tolist()\n",
        "#     random.shuffle(labeled_nodes)\n",
        "#     num = int(len(labeled_nodes) * ratios[-1])\n",
        "#     if num > 0:\n",
        "#         labeled_nodes = labeled_nodes[:num]\n",
        "#     nodes_list = [set(labeled_nodes)]\n",
        "#     edges_list = []\n",
        "#     all_nodes = labeled_nodes\n",
        "#     for k in range(K):\n",
        "#         # Get nodes and edges from the previous layer\n",
        "#         nodes, all_nodes, edges = \\\n",
        "#             sample_neighbors(nodes_list[-1], graph.G, ratios[len(ratios) - k - 2], all_nodes)\n",
        "#         nodes_list.append(nodes)\n",
        "#         edges_list.append(edges)\n",
        "    \n",
        "#     # Reverse the lists\n",
        "#     nodes_list.reverse()\n",
        "#     edges_list.reverse()\n",
        "\n",
        "#     relabled_edges_list, relabeled_all_nodes, relabeled_labeled_nodes = \\\n",
        "#         relable(all_nodes, labeled_nodes, edges_list)\n",
        "\n",
        "#     node_index = nodes_to_tensor(relabeled_all_nodes)\n",
        "#     # All node features that will be used\n",
        "#     node_feature = graph.node_feature[node_index]\n",
        "#     edge_indices = [edges_to_tensor(edges) for edges in relabled_edges_list]\n",
        "#     node_label_index = nodes_to_tensor(relabeled_labeled_nodes)\n",
        "#     log = \"Sampled {} nodes, {} edges, {} labeled nodes\"\n",
        "#     print(log.format(node_feature.shape[0], edge_indices[0].shape[1] // 2, node_label_index.shape[0]))\n",
        "#     return node_feature, edge_indices, node_label_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_neighbors(nodes, G, ratio, all_nodes):\n",
        "  # This function takes a set of nodes, a NetworkX graph G and neighbor sampling ratio.\n",
        "  # It will return sampled neighbors (unioned with input nodes) and edges between.\n",
        "\n",
        "  neighbors = set()\n",
        "  edges = []\n",
        "\n",
        "  for node in nodes:\n",
        "    neighbors_list = list(nx.neighbors(G, node))\n",
        "\n",
        "    # We only sample the (ratio * number of neighbors) neighbors\n",
        "    num = int(len(neighbors_list) * ratio)\n",
        "\n",
        "    if num > 0:\n",
        "      # Random shuffle the neighbors\n",
        "      random.shuffle(neighbors_list)\n",
        "      neighbors_list = neighbors_list[:num]\n",
        "      for neighbor in neighbors_list:\n",
        "        # Add neighbors\n",
        "        neighbors.add(neighbor)\n",
        "        edges.append((neighbor, node))\n",
        "  return neighbors, neighbors.union(all_nodes), edges"
      ],
      "metadata": {
        "id": "6DqXI5NHiZjT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nodes_to_tensor(nodes):\n",
        "  # This function transform a set of nodes to node index tensor.\n",
        "  node_label_index = torch.tensor(list(nodes), dtype=torch.long)\n",
        "  return node_label_index"
      ],
      "metadata": {
        "id": "6qSn5J1WjtNh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edges_to_tensor(edges):\n",
        "  # This function transform a set of edges to edge index tensor\n",
        "  edge_index = torch.tensor(list(edges),dtype=torch.long)\n",
        "  edge_index = torch.cat([edge_index, torch.flip(edge_index, [1])], dim=0)\n",
        "  edge_index = edge_index.permute(1, 0)\n",
        "  return edge_index"
      ],
      "metadata": {
        "id": "HXoYH1UGj5A0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relable(nodes, labeled_nodes, edges_list):\n",
        "    # Relable the nodes, labeled_nodes and edges_list\n",
        "    relabled_edges_list = []\n",
        "    sorted_nodes = sorted(nodes)\n",
        "    node_mapping = {node : i for i, node in enumerate(sorted_nodes)}\n",
        "    for orig_edges in edges_list:\n",
        "        relabeled_edges = []\n",
        "        for edge in orig_edges:\n",
        "            relabeled_edges.append((node_mapping[edge[0]], node_mapping[edge[1]]))\n",
        "        relabled_edges_list.append(relabeled_edges)\n",
        "    relabeled_labeled_nodes = [node_mapping[node] for node in labeled_nodes]\n",
        "    relabeled_nodes = [node_mapping[node] for node in nodes]\n",
        "    return relabled_edges_list, relabeled_nodes, relabeled_labeled_nodes"
      ],
      "metadata": {
        "id": "_LOBuWqdlbLt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neighbor_sampling(graph, K=2, ratios=(0.1, 0.1, 0.1)):\n",
        "    # This function takes a DeepSNAP graph, K the number of GNN layers, and neighbor \n",
        "    # sampling ratios for each layer. This function returns relabeled node feature, \n",
        "    # edge indices and node_label_index\n",
        "\n",
        "    assert K + 1 == len(ratios)\n",
        "\n",
        "    labeled_nodes = graph.node_label_index.tolist()\n",
        "    random.shuffle(labeled_nodes)\n",
        "    num = int(len(labeled_nodes) * ratios[-1])\n",
        "    if num > 0:\n",
        "        labeled_nodes = labeled_nodes[:num]\n",
        "    nodes_list = [set(labeled_nodes)]\n",
        "    edges_list = []\n",
        "    all_nodes = labeled_nodes\n",
        "    for k in range(K):\n",
        "        # Get nodes and edges from the previous layer\n",
        "        nodes, all_nodes, edges = \\\n",
        "            sample_neighbors(nodes_list[-1], graph.G, ratios[len(ratios) - k - 2], all_nodes)\n",
        "        nodes_list.append(nodes)\n",
        "        edges_list.append(edges)\n",
        "    \n",
        "    # Reverse the lists\n",
        "    nodes_list.reverse()\n",
        "    edges_list.reverse()\n",
        "\n",
        "    relabled_edges_list, relabeled_all_nodes, relabeled_labeled_nodes = \\\n",
        "        relable(all_nodes, labeled_nodes, edges_list)\n",
        "\n",
        "    node_index = nodes_to_tensor(relabeled_all_nodes)\n",
        "    # All node features that will be used\n",
        "    node_feature = graph.node_feature[node_index]\n",
        "    edge_indices = [edges_to_tensor(edges) for edges in relabled_edges_list]\n",
        "    node_label_index = nodes_to_tensor(relabeled_labeled_nodes)\n",
        "    log = \"Sampled {} nodes, {} edges, {} labeled nodes\"\n",
        "    print(log.format(node_feature.shape[0], edge_indices[0].shape[1] // 2, node_label_index.shape[0]))\n",
        "    return node_feature, edge_indices, node_label_index"
      ],
      "metadata": {
        "id": "AjWxe7wakJxx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bX1XC1dqiZlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooy6Hcf7TIhI"
      },
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSmZhpzPTGPY"
      },
      "source": [
        "def train(train_graphs, val_graphs, args, model, optimizer, mode=\"batch\"):\n",
        "    best_val = 0\n",
        "    best_model = None\n",
        "    accs = []\n",
        "    graph_train = train_graphs[0]\n",
        "    graph_train.to(args['device'])\n",
        "    for epoch in range(1, 1 + args['epochs']):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        if mode == \"batch\":\n",
        "            node_feature, edge_indices, node_label_index = neighbor_sampling(graph_train, args['num_layers'], args['ratios'])\n",
        "            node_feature = node_feature.to(args['device'])\n",
        "            node_label_index = node_label_index.to(args['device'])\n",
        "            for i in range(len(edge_indices)):\n",
        "                edge_indices[i] = edge_indices[i].to(args['device'])\n",
        "            pred = model([edge_indices, node_feature])\n",
        "            pred = pred[node_label_index]\n",
        "            label = graph_train.node_label[node_label_index]\n",
        "        elif mode == \"community\":\n",
        "            graph = random.choice(train_graphs)\n",
        "            graph = graph.to(args['device'])\n",
        "            pred = model(graph, mode=\"all\")\n",
        "            pred = pred[graph.node_label_index]\n",
        "            label = graph.node_label[graph.node_label_index]\n",
        "        else:\n",
        "            pred = model(graph_train, mode=\"all\")\n",
        "            label = graph_train.node_label\n",
        "            pred = pred[graph_train.node_label_index]\n",
        "        loss = F.nll_loss(pred, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc, val_acc, test_acc = test(val_graphs, model)\n",
        "        accs.append((train_acc, val_acc, test_acc))\n",
        "        if val_acc > best_val:\n",
        "            best_val = val_acc\n",
        "            best_model = copy.deepcopy(model)\n",
        "        print(f'Epoch: {epoch:02d}, '\n",
        "              f'Loss: {loss:.4f}, '\n",
        "              f'Train: {100 * train_acc:.2f}%, '\n",
        "              f'Valid: {100 * val_acc:.2f}% '\n",
        "              f'Test: {100 * test_acc:.2f}%')\n",
        "    return best_model, accs\n",
        "\n",
        "def test(graphs, model):\n",
        "    model.eval()\n",
        "    accs = []\n",
        "    for graph in graphs:\n",
        "        graph = graph.to(args['device'])\n",
        "        pred = model(graph, mode=\"all\")\n",
        "        label = graph.node_label\n",
        "        pred = pred[graph.node_label_index].max(1)[1]\n",
        "        acc = pred.eq(label).sum().item()\n",
        "        acc /= len(label)\n",
        "        accs.append(acc)\n",
        "    return accs"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UfXvt-ballYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xuuJ0kt0llbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bUuoW9XOllkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV7i0v0ETKzf"
      },
      "source": [
        "args = {\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'dropout': 0.5,\n",
        "    'num_layers': 2,\n",
        "    'hidden_size': 64,\n",
        "    'lr': 0.005,\n",
        "    'epochs': 50,\n",
        "    'ratios': (0.8, 0.8, 1),\n",
        "}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLpRYKbnTQnj"
      },
      "source": [
        "## Full-Batch Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMGGjbJBTOo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99730d3-2b63-422d-c98c-68dc8282ffe2"
      },
      "source": [
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "\n",
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "graphs = [graph_train, graph_val, graph_test]\n",
        "all_best_model, all_accs = train(graphs, graphs, args, model, optimizer, mode=\"all\")\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], all_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index fields: val_mask ignored.\n",
            "Index fields: test_mask ignored.\n",
            "Index fields: train_mask ignored.\n",
            "Epoch: 01, Loss: 2.0434, Train: 58.57%, Valid: 32.20% Test: 31.40%\n",
            "Epoch: 02, Loss: 1.1647, Train: 93.57%, Valid: 42.00% Test: 42.30%\n",
            "Epoch: 03, Loss: 0.6616, Train: 98.57%, Valid: 50.40% Test: 51.00%\n",
            "Epoch: 04, Loss: 0.3845, Train: 100.00%, Valid: 56.80% Test: 57.50%\n",
            "Epoch: 05, Loss: 0.1747, Train: 100.00%, Valid: 61.00% Test: 62.50%\n",
            "Epoch: 06, Loss: 0.0901, Train: 100.00%, Valid: 63.40% Test: 66.30%\n",
            "Epoch: 07, Loss: 0.0441, Train: 100.00%, Valid: 65.60% Test: 68.30%\n",
            "Epoch: 08, Loss: 0.0305, Train: 100.00%, Valid: 66.40% Test: 71.30%\n",
            "Epoch: 09, Loss: 0.0149, Train: 100.00%, Valid: 67.40% Test: 72.10%\n",
            "Epoch: 10, Loss: 0.0085, Train: 100.00%, Valid: 67.60% Test: 72.40%\n",
            "Epoch: 11, Loss: 0.0058, Train: 100.00%, Valid: 68.80% Test: 72.90%\n",
            "Epoch: 12, Loss: 0.0055, Train: 100.00%, Valid: 70.20% Test: 73.30%\n",
            "Epoch: 13, Loss: 0.0027, Train: 100.00%, Valid: 70.80% Test: 73.50%\n",
            "Epoch: 14, Loss: 0.0010, Train: 100.00%, Valid: 71.20% Test: 74.20%\n",
            "Epoch: 15, Loss: 0.0020, Train: 100.00%, Valid: 71.60% Test: 74.70%\n",
            "Epoch: 16, Loss: 0.0016, Train: 100.00%, Valid: 71.80% Test: 74.80%\n",
            "Epoch: 17, Loss: 0.0076, Train: 100.00%, Valid: 71.80% Test: 75.10%\n",
            "Epoch: 18, Loss: 0.0068, Train: 100.00%, Valid: 71.80% Test: 75.50%\n",
            "Epoch: 19, Loss: 0.0017, Train: 100.00%, Valid: 71.80% Test: 76.10%\n",
            "Epoch: 20, Loss: 0.0042, Train: 100.00%, Valid: 72.00% Test: 75.80%\n",
            "Epoch: 21, Loss: 0.0053, Train: 100.00%, Valid: 72.40% Test: 76.10%\n",
            "Epoch: 22, Loss: 0.0013, Train: 100.00%, Valid: 72.80% Test: 76.20%\n",
            "Epoch: 23, Loss: 0.0001, Train: 100.00%, Valid: 73.00% Test: 76.30%\n",
            "Epoch: 24, Loss: 0.0004, Train: 100.00%, Valid: 73.20% Test: 76.40%\n",
            "Epoch: 25, Loss: 0.0003, Train: 100.00%, Valid: 73.60% Test: 76.40%\n",
            "Epoch: 26, Loss: 0.0003, Train: 100.00%, Valid: 73.40% Test: 76.20%\n",
            "Epoch: 27, Loss: 0.0004, Train: 100.00%, Valid: 73.40% Test: 76.10%\n",
            "Epoch: 28, Loss: 0.0003, Train: 100.00%, Valid: 73.80% Test: 76.20%\n",
            "Epoch: 29, Loss: 0.0002, Train: 100.00%, Valid: 74.00% Test: 76.20%\n",
            "Epoch: 30, Loss: 0.0007, Train: 100.00%, Valid: 74.00% Test: 76.10%\n",
            "Epoch: 31, Loss: 0.0003, Train: 100.00%, Valid: 74.20% Test: 76.10%\n",
            "Epoch: 32, Loss: 0.0001, Train: 100.00%, Valid: 74.20% Test: 76.20%\n",
            "Epoch: 33, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 76.10%\n",
            "Epoch: 34, Loss: 0.0001, Train: 100.00%, Valid: 74.00% Test: 76.10%\n",
            "Epoch: 35, Loss: 0.0001, Train: 100.00%, Valid: 74.00% Test: 76.50%\n",
            "Epoch: 36, Loss: 0.0002, Train: 100.00%, Valid: 74.00% Test: 76.30%\n",
            "Epoch: 37, Loss: 0.0003, Train: 100.00%, Valid: 74.20% Test: 76.20%\n",
            "Epoch: 38, Loss: 0.0000, Train: 100.00%, Valid: 74.40% Test: 76.30%\n",
            "Epoch: 39, Loss: 0.0005, Train: 100.00%, Valid: 74.40% Test: 76.30%\n",
            "Epoch: 40, Loss: 0.0010, Train: 100.00%, Valid: 74.40% Test: 76.30%\n",
            "Epoch: 41, Loss: 0.0003, Train: 100.00%, Valid: 74.20% Test: 76.30%\n",
            "Epoch: 42, Loss: 0.0011, Train: 100.00%, Valid: 74.20% Test: 76.20%\n",
            "Epoch: 43, Loss: 0.0001, Train: 100.00%, Valid: 74.20% Test: 76.20%\n",
            "Epoch: 44, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 76.00%\n",
            "Epoch: 45, Loss: 0.0001, Train: 100.00%, Valid: 74.20% Test: 75.90%\n",
            "Epoch: 46, Loss: 0.0001, Train: 100.00%, Valid: 74.20% Test: 75.90%\n",
            "Epoch: 47, Loss: 0.0000, Train: 100.00%, Valid: 74.20% Test: 75.70%\n",
            "Epoch: 48, Loss: 0.0001, Train: 100.00%, Valid: 74.40% Test: 75.60%\n",
            "Epoch: 49, Loss: 0.0001, Train: 100.00%, Valid: 74.60% Test: 75.50%\n",
            "Epoch: 50, Loss: 0.0001, Train: 100.00%, Valid: 74.40% Test: 75.40%\n",
            "Best model: Train: 100.00%, Valid: 74.60% Test: 75.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWkGiwB6Thr4"
      },
      "source": [
        "## Sampling with Ratios 0.8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWusJ9u3Tfhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb3d459-cb26-48f9-f0de-56433ac03a1b"
      },
      "source": [
        "args['ratios'] = (0.8, 0.8, 1)\n",
        "\n",
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "\n",
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "graphs = [graph_train, graph_val, graph_test]\n",
        "batch_best_model, batch_accs = train(graphs, graphs, args, model, optimizer)\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], batch_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index fields: val_mask ignored.\n",
            "Index fields: test_mask ignored.\n",
            "Index fields: train_mask ignored.\n",
            "Sampled 1306 nodes, 1972 edges, 140 labeled nodes\n",
            "Epoch: 01, Loss: 2.0278, Train: 17.86%, Valid: 7.60% Test: 9.50%\n",
            "Sampled 1307 nodes, 1990 edges, 140 labeled nodes\n",
            "Epoch: 02, Loss: 1.6415, Train: 50.71%, Valid: 12.40% Test: 13.20%\n",
            "Sampled 1308 nodes, 2014 edges, 140 labeled nodes\n",
            "Epoch: 03, Loss: 1.3203, Train: 72.86%, Valid: 19.80% Test: 18.80%\n",
            "Sampled 1321 nodes, 2027 edges, 140 labeled nodes\n",
            "Epoch: 04, Loss: 1.1004, Train: 87.14%, Valid: 24.80% Test: 25.70%\n",
            "Sampled 1329 nodes, 2015 edges, 140 labeled nodes\n",
            "Epoch: 05, Loss: 0.8545, Train: 92.14%, Valid: 27.80% Test: 30.50%\n",
            "Sampled 1324 nodes, 1985 edges, 140 labeled nodes\n",
            "Epoch: 06, Loss: 0.6173, Train: 97.14%, Valid: 30.40% Test: 32.60%\n",
            "Sampled 1309 nodes, 1973 edges, 140 labeled nodes\n",
            "Epoch: 07, Loss: 0.4972, Train: 97.14%, Valid: 32.20% Test: 35.70%\n",
            "Sampled 1303 nodes, 1921 edges, 140 labeled nodes\n",
            "Epoch: 08, Loss: 0.3756, Train: 97.86%, Valid: 34.40% Test: 37.30%\n",
            "Sampled 1303 nodes, 1998 edges, 140 labeled nodes\n",
            "Epoch: 09, Loss: 0.2663, Train: 97.86%, Valid: 36.40% Test: 39.30%\n",
            "Sampled 1276 nodes, 1935 edges, 140 labeled nodes\n",
            "Epoch: 10, Loss: 0.2276, Train: 97.86%, Valid: 38.80% Test: 41.40%\n",
            "Sampled 1298 nodes, 1969 edges, 140 labeled nodes\n",
            "Epoch: 11, Loss: 0.1539, Train: 97.86%, Valid: 39.40% Test: 42.90%\n",
            "Sampled 1307 nodes, 2018 edges, 140 labeled nodes\n",
            "Epoch: 12, Loss: 0.1297, Train: 97.86%, Valid: 40.60% Test: 43.90%\n",
            "Sampled 1308 nodes, 2011 edges, 140 labeled nodes\n",
            "Epoch: 13, Loss: 0.1203, Train: 98.57%, Valid: 41.00% Test: 44.40%\n",
            "Sampled 1305 nodes, 1985 edges, 140 labeled nodes\n",
            "Epoch: 14, Loss: 0.1122, Train: 100.00%, Valid: 41.80% Test: 45.70%\n",
            "Sampled 1301 nodes, 1969 edges, 140 labeled nodes\n",
            "Epoch: 15, Loss: 0.0875, Train: 100.00%, Valid: 43.00% Test: 45.90%\n",
            "Sampled 1336 nodes, 1987 edges, 140 labeled nodes\n",
            "Epoch: 16, Loss: 0.0751, Train: 100.00%, Valid: 44.20% Test: 47.10%\n",
            "Sampled 1321 nodes, 2014 edges, 140 labeled nodes\n",
            "Epoch: 17, Loss: 0.0546, Train: 100.00%, Valid: 44.20% Test: 47.40%\n",
            "Sampled 1333 nodes, 2040 edges, 140 labeled nodes\n",
            "Epoch: 18, Loss: 0.0416, Train: 100.00%, Valid: 44.20% Test: 48.40%\n",
            "Sampled 1294 nodes, 1939 edges, 140 labeled nodes\n",
            "Epoch: 19, Loss: 0.0551, Train: 100.00%, Valid: 44.20% Test: 49.60%\n",
            "Sampled 1294 nodes, 1954 edges, 140 labeled nodes\n",
            "Epoch: 20, Loss: 0.0601, Train: 100.00%, Valid: 43.80% Test: 50.20%\n",
            "Sampled 1325 nodes, 1947 edges, 140 labeled nodes\n",
            "Epoch: 21, Loss: 0.0200, Train: 100.00%, Valid: 44.60% Test: 50.70%\n",
            "Sampled 1311 nodes, 1932 edges, 140 labeled nodes\n",
            "Epoch: 22, Loss: 0.0407, Train: 100.00%, Valid: 44.00% Test: 50.90%\n",
            "Sampled 1308 nodes, 1954 edges, 140 labeled nodes\n",
            "Epoch: 23, Loss: 0.0351, Train: 100.00%, Valid: 44.20% Test: 51.20%\n",
            "Sampled 1300 nodes, 1928 edges, 140 labeled nodes\n",
            "Epoch: 24, Loss: 0.0171, Train: 100.00%, Valid: 44.80% Test: 51.50%\n",
            "Sampled 1306 nodes, 1992 edges, 140 labeled nodes\n",
            "Epoch: 25, Loss: 0.0251, Train: 100.00%, Valid: 45.20% Test: 52.00%\n",
            "Sampled 1324 nodes, 2031 edges, 140 labeled nodes\n",
            "Epoch: 26, Loss: 0.0116, Train: 100.00%, Valid: 45.00% Test: 51.90%\n",
            "Sampled 1324 nodes, 1993 edges, 140 labeled nodes\n",
            "Epoch: 27, Loss: 0.0381, Train: 100.00%, Valid: 44.80% Test: 51.90%\n",
            "Sampled 1316 nodes, 1953 edges, 140 labeled nodes\n",
            "Epoch: 28, Loss: 0.0053, Train: 100.00%, Valid: 44.20% Test: 52.10%\n",
            "Sampled 1299 nodes, 2014 edges, 140 labeled nodes\n",
            "Epoch: 29, Loss: 0.0216, Train: 100.00%, Valid: 44.60% Test: 52.20%\n",
            "Sampled 1306 nodes, 1970 edges, 140 labeled nodes\n",
            "Epoch: 30, Loss: 0.0089, Train: 100.00%, Valid: 44.80% Test: 51.90%\n",
            "Sampled 1335 nodes, 1998 edges, 140 labeled nodes\n",
            "Epoch: 31, Loss: 0.0518, Train: 100.00%, Valid: 45.00% Test: 51.80%\n",
            "Sampled 1287 nodes, 1952 edges, 140 labeled nodes\n",
            "Epoch: 32, Loss: 0.0075, Train: 100.00%, Valid: 44.80% Test: 51.70%\n",
            "Sampled 1295 nodes, 1937 edges, 140 labeled nodes\n",
            "Epoch: 33, Loss: 0.0057, Train: 100.00%, Valid: 44.80% Test: 51.50%\n",
            "Sampled 1335 nodes, 2053 edges, 140 labeled nodes\n",
            "Epoch: 34, Loss: 0.0093, Train: 100.00%, Valid: 44.80% Test: 51.40%\n",
            "Sampled 1273 nodes, 1938 edges, 140 labeled nodes\n",
            "Epoch: 35, Loss: 0.0064, Train: 100.00%, Valid: 45.00% Test: 51.30%\n",
            "Sampled 1323 nodes, 2035 edges, 140 labeled nodes\n",
            "Epoch: 36, Loss: 0.0202, Train: 100.00%, Valid: 45.80% Test: 51.30%\n",
            "Sampled 1296 nodes, 1960 edges, 140 labeled nodes\n",
            "Epoch: 37, Loss: 0.0222, Train: 100.00%, Valid: 45.40% Test: 51.00%\n",
            "Sampled 1308 nodes, 1976 edges, 140 labeled nodes\n",
            "Epoch: 38, Loss: 0.0196, Train: 100.00%, Valid: 45.80% Test: 51.00%\n",
            "Sampled 1313 nodes, 2027 edges, 140 labeled nodes\n",
            "Epoch: 39, Loss: 0.0148, Train: 100.00%, Valid: 46.00% Test: 51.30%\n",
            "Sampled 1285 nodes, 1928 edges, 140 labeled nodes\n",
            "Epoch: 40, Loss: 0.0177, Train: 100.00%, Valid: 45.80% Test: 51.30%\n",
            "Sampled 1272 nodes, 1867 edges, 140 labeled nodes\n",
            "Epoch: 41, Loss: 0.0110, Train: 100.00%, Valid: 45.60% Test: 51.40%\n",
            "Sampled 1291 nodes, 1965 edges, 140 labeled nodes\n",
            "Epoch: 42, Loss: 0.0018, Train: 100.00%, Valid: 45.20% Test: 51.60%\n",
            "Sampled 1307 nodes, 1959 edges, 140 labeled nodes\n",
            "Epoch: 43, Loss: 0.0113, Train: 100.00%, Valid: 46.00% Test: 51.60%\n",
            "Sampled 1330 nodes, 1995 edges, 140 labeled nodes\n",
            "Epoch: 44, Loss: 0.0144, Train: 100.00%, Valid: 45.80% Test: 51.70%\n",
            "Sampled 1373 nodes, 2042 edges, 140 labeled nodes\n",
            "Epoch: 45, Loss: 0.0642, Train: 100.00%, Valid: 46.00% Test: 51.80%\n",
            "Sampled 1311 nodes, 2026 edges, 140 labeled nodes\n",
            "Epoch: 46, Loss: 0.0069, Train: 100.00%, Valid: 46.00% Test: 51.90%\n",
            "Sampled 1315 nodes, 1927 edges, 140 labeled nodes\n",
            "Epoch: 47, Loss: 0.0032, Train: 100.00%, Valid: 46.20% Test: 51.80%\n",
            "Sampled 1314 nodes, 1964 edges, 140 labeled nodes\n",
            "Epoch: 48, Loss: 0.0935, Train: 100.00%, Valid: 47.00% Test: 51.60%\n",
            "Sampled 1280 nodes, 1939 edges, 140 labeled nodes\n",
            "Epoch: 49, Loss: 0.0385, Train: 100.00%, Valid: 48.20% Test: 51.90%\n",
            "Sampled 1284 nodes, 1950 edges, 140 labeled nodes\n",
            "Epoch: 50, Loss: 0.0126, Train: 100.00%, Valid: 48.20% Test: 51.80%\n",
            "Best model: Train: 100.00%, Valid: 48.20% Test: 51.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_FjkNHDT4c6"
      },
      "source": [
        "## Sampling with Ratios 0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "booJ6DASTjO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3861725-af10-457b-921e-d88b97fb139c"
      },
      "source": [
        "# Change the ratio to 0.3\n",
        "args['ratios'] = (0.3, 0.3, 1)\n",
        "\n",
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "\n",
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "graphs = [graph_train, graph_val, graph_test]\n",
        "batch_best_model, batch_accs_1 = train(graphs, graphs, args, model, optimizer)\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], batch_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index fields: val_mask ignored.\n",
            "Index fields: test_mask ignored.\n",
            "Index fields: train_mask ignored.\n",
            "Sampled 408 nodes, 208 edges, 140 labeled nodes\n",
            "Epoch: 01, Loss: 1.9813, Train: 14.29%, Valid: 16.20% Test: 14.90%\n",
            "Sampled 415 nodes, 230 edges, 140 labeled nodes\n",
            "Epoch: 02, Loss: 1.9956, Train: 15.00%, Valid: 16.00% Test: 14.90%\n",
            "Sampled 440 nodes, 249 edges, 140 labeled nodes\n",
            "Epoch: 03, Loss: 1.8779, Train: 16.43%, Valid: 16.20% Test: 15.00%\n",
            "Sampled 417 nodes, 239 edges, 140 labeled nodes\n",
            "Epoch: 04, Loss: 1.8178, Train: 17.86%, Valid: 16.40% Test: 15.10%\n",
            "Sampled 458 nodes, 266 edges, 140 labeled nodes\n",
            "Epoch: 05, Loss: 1.7818, Train: 22.86%, Valid: 16.40% Test: 15.70%\n",
            "Sampled 440 nodes, 258 edges, 140 labeled nodes\n",
            "Epoch: 06, Loss: 1.9198, Train: 30.71%, Valid: 17.00% Test: 16.30%\n",
            "Sampled 449 nodes, 254 edges, 140 labeled nodes\n",
            "Epoch: 07, Loss: 1.8868, Train: 34.29%, Valid: 17.80% Test: 17.00%\n",
            "Sampled 439 nodes, 257 edges, 140 labeled nodes\n",
            "Epoch: 08, Loss: 1.8153, Train: 38.57%, Valid: 19.40% Test: 18.10%\n",
            "Sampled 426 nodes, 238 edges, 140 labeled nodes\n",
            "Epoch: 09, Loss: 1.7954, Train: 45.71%, Valid: 22.40% Test: 20.60%\n",
            "Sampled 444 nodes, 248 edges, 140 labeled nodes\n",
            "Epoch: 10, Loss: 1.7739, Train: 52.14%, Valid: 24.00% Test: 23.60%\n",
            "Sampled 435 nodes, 247 edges, 140 labeled nodes\n",
            "Epoch: 11, Loss: 1.6756, Train: 52.14%, Valid: 29.00% Test: 28.30%\n",
            "Sampled 430 nodes, 249 edges, 140 labeled nodes\n",
            "Epoch: 12, Loss: 1.6684, Train: 58.57%, Valid: 30.40% Test: 30.70%\n",
            "Sampled 360 nodes, 168 edges, 140 labeled nodes\n",
            "Epoch: 13, Loss: 1.7119, Train: 56.43%, Valid: 31.80% Test: 32.70%\n",
            "Sampled 432 nodes, 238 edges, 140 labeled nodes\n",
            "Epoch: 14, Loss: 1.7243, Train: 55.00%, Valid: 31.20% Test: 34.80%\n",
            "Sampled 382 nodes, 185 edges, 140 labeled nodes\n",
            "Epoch: 15, Loss: 1.7389, Train: 57.14%, Valid: 30.80% Test: 35.70%\n",
            "Sampled 456 nodes, 287 edges, 140 labeled nodes\n",
            "Epoch: 16, Loss: 1.7034, Train: 56.43%, Valid: 29.60% Test: 35.70%\n",
            "Sampled 435 nodes, 242 edges, 140 labeled nodes\n",
            "Epoch: 17, Loss: 1.6825, Train: 57.86%, Valid: 28.80% Test: 34.60%\n",
            "Sampled 397 nodes, 214 edges, 140 labeled nodes\n",
            "Epoch: 18, Loss: 1.6553, Train: 57.14%, Valid: 26.80% Test: 33.50%\n",
            "Sampled 391 nodes, 203 edges, 140 labeled nodes\n",
            "Epoch: 19, Loss: 1.6203, Train: 55.71%, Valid: 26.60% Test: 32.60%\n",
            "Sampled 402 nodes, 207 edges, 140 labeled nodes\n",
            "Epoch: 20, Loss: 1.6601, Train: 54.29%, Valid: 27.00% Test: 32.20%\n",
            "Sampled 429 nodes, 241 edges, 140 labeled nodes\n",
            "Epoch: 21, Loss: 1.6196, Train: 54.29%, Valid: 26.20% Test: 32.40%\n",
            "Sampled 428 nodes, 245 edges, 140 labeled nodes\n",
            "Epoch: 22, Loss: 1.5502, Train: 55.00%, Valid: 27.00% Test: 31.60%\n",
            "Sampled 395 nodes, 217 edges, 140 labeled nodes\n",
            "Epoch: 23, Loss: 1.6167, Train: 55.71%, Valid: 26.60% Test: 30.90%\n",
            "Sampled 360 nodes, 154 edges, 140 labeled nodes\n",
            "Epoch: 24, Loss: 1.5538, Train: 53.57%, Valid: 25.80% Test: 30.30%\n",
            "Sampled 415 nodes, 232 edges, 140 labeled nodes\n",
            "Epoch: 25, Loss: 1.5115, Train: 54.29%, Valid: 26.40% Test: 30.60%\n",
            "Sampled 400 nodes, 205 edges, 140 labeled nodes\n",
            "Epoch: 26, Loss: 1.5440, Train: 55.00%, Valid: 26.00% Test: 31.70%\n",
            "Sampled 449 nodes, 262 edges, 140 labeled nodes\n",
            "Epoch: 27, Loss: 1.5077, Train: 56.43%, Valid: 28.20% Test: 32.50%\n",
            "Sampled 421 nodes, 229 edges, 140 labeled nodes\n",
            "Epoch: 28, Loss: 1.5189, Train: 57.14%, Valid: 31.00% Test: 33.20%\n",
            "Sampled 445 nodes, 282 edges, 140 labeled nodes\n",
            "Epoch: 29, Loss: 1.4874, Train: 57.86%, Valid: 32.00% Test: 34.10%\n",
            "Sampled 418 nodes, 238 edges, 140 labeled nodes\n",
            "Epoch: 30, Loss: 1.5051, Train: 59.29%, Valid: 33.00% Test: 34.30%\n",
            "Sampled 396 nodes, 213 edges, 140 labeled nodes\n",
            "Epoch: 31, Loss: 1.5871, Train: 60.71%, Valid: 34.20% Test: 35.30%\n",
            "Sampled 453 nodes, 272 edges, 140 labeled nodes\n",
            "Epoch: 32, Loss: 1.6213, Train: 62.86%, Valid: 35.00% Test: 36.40%\n",
            "Sampled 435 nodes, 267 edges, 140 labeled nodes\n",
            "Epoch: 33, Loss: 1.5380, Train: 63.57%, Valid: 36.60% Test: 37.10%\n",
            "Sampled 394 nodes, 209 edges, 140 labeled nodes\n",
            "Epoch: 34, Loss: 1.5317, Train: 62.14%, Valid: 37.20% Test: 37.30%\n",
            "Sampled 412 nodes, 213 edges, 140 labeled nodes\n",
            "Epoch: 35, Loss: 1.6102, Train: 62.14%, Valid: 37.40% Test: 38.50%\n",
            "Sampled 417 nodes, 244 edges, 140 labeled nodes\n",
            "Epoch: 36, Loss: 1.6359, Train: 63.57%, Valid: 37.80% Test: 39.30%\n",
            "Sampled 394 nodes, 205 edges, 140 labeled nodes\n",
            "Epoch: 37, Loss: 1.5506, Train: 65.00%, Valid: 38.20% Test: 40.00%\n",
            "Sampled 418 nodes, 237 edges, 140 labeled nodes\n",
            "Epoch: 38, Loss: 1.5337, Train: 65.00%, Valid: 37.80% Test: 40.60%\n",
            "Sampled 425 nodes, 242 edges, 140 labeled nodes\n",
            "Epoch: 39, Loss: 1.4269, Train: 65.00%, Valid: 38.20% Test: 41.20%\n",
            "Sampled 443 nodes, 264 edges, 140 labeled nodes\n",
            "Epoch: 40, Loss: 1.6313, Train: 65.71%, Valid: 38.00% Test: 41.20%\n",
            "Sampled 355 nodes, 166 edges, 140 labeled nodes\n",
            "Epoch: 41, Loss: 1.4053, Train: 63.57%, Valid: 36.40% Test: 40.90%\n",
            "Sampled 460 nodes, 277 edges, 140 labeled nodes\n",
            "Epoch: 42, Loss: 1.5056, Train: 63.57%, Valid: 36.40% Test: 41.00%\n",
            "Sampled 424 nodes, 242 edges, 140 labeled nodes\n",
            "Epoch: 43, Loss: 1.6128, Train: 63.57%, Valid: 36.00% Test: 41.60%\n",
            "Sampled 427 nodes, 234 edges, 140 labeled nodes\n",
            "Epoch: 44, Loss: 1.6827, Train: 64.29%, Valid: 35.40% Test: 40.40%\n",
            "Sampled 397 nodes, 209 edges, 140 labeled nodes\n",
            "Epoch: 45, Loss: 1.4653, Train: 65.00%, Valid: 34.60% Test: 40.00%\n",
            "Sampled 397 nodes, 209 edges, 140 labeled nodes\n",
            "Epoch: 46, Loss: 1.5585, Train: 65.00%, Valid: 34.20% Test: 40.10%\n",
            "Sampled 424 nodes, 232 edges, 140 labeled nodes\n",
            "Epoch: 47, Loss: 1.5677, Train: 65.71%, Valid: 34.40% Test: 39.90%\n",
            "Sampled 391 nodes, 197 edges, 140 labeled nodes\n",
            "Epoch: 48, Loss: 1.5513, Train: 66.43%, Valid: 36.00% Test: 39.20%\n",
            "Sampled 446 nodes, 273 edges, 140 labeled nodes\n",
            "Epoch: 49, Loss: 1.6022, Train: 66.43%, Valid: 36.80% Test: 39.70%\n",
            "Sampled 459 nodes, 275 edges, 140 labeled nodes\n",
            "Epoch: 50, Loss: 1.5311, Train: 65.71%, Valid: 37.00% Test: 41.50%\n",
            "Best model: Train: 65.00%, Valid: 38.20% Test: 40.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EePAvNlGUM2K"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7etNAkXAT55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "ef61ff56-ceb9-4774-b26e-83eec4b902e9"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "batch_results = np.array(batch_accs)\n",
        "batch_results_1 = np.array(batch_accs_1)\n",
        "all_results = np.array(all_accs)\n",
        "\n",
        "x = np.arange(1, 51)\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "\n",
        "plt.plot(x, batch_results[:, 0], label=\"Batch 0.8 Train\")\n",
        "plt.plot(x, batch_results[:, 1], label=\"Batch 0.8 Validation\")\n",
        "plt.plot(x, batch_results[:, 2], label=\"Batch 0.8 Test\")\n",
        "plt.plot(x, batch_results_1[:, 0], label=\"Batch 0.3 Train\")\n",
        "plt.plot(x, batch_results_1[:, 1], label=\"Batch 0.3 Validation\")\n",
        "plt.plot(x, batch_results_1[:, 2], label=\"Batch 0.3 Test\")\n",
        "plt.plot(x, all_results[:, 0], label=\"All Train\")\n",
        "plt.plot(x, all_results[:, 1], label=\"All Validation\")\n",
        "plt.plot(x, all_results[:, 2], label=\"All Test\")\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkA7-0groq7q"
      },
      "source": [
        "Here all accuracies are evaluated on the full-batch mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iee0U8KGURc8"
      },
      "source": [
        "# 3 Cluster Sampling\n",
        "\n",
        "Instead of the neighbor sampling, we can use another approach, subgraph (cluster) sampling, to scale up GNN. This approach is proposed in Cluster-GCN ([Chiang et al. (2019)](https://arxiv.org/abs/1905.07953)).\n",
        "\n",
        "In this section, we will implement vanilla Cluster-GCN and experiment with 3 different community partition algorithms.\n",
        "\n",
        "Notice that this section requires you have run the `Setup`, `GNN Model` and `Training and Testing` cells of the last section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BXjP79gUYir"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGQ_VKp8UOEm"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import community as community_louvain\n",
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from deepsnap.graph import Graph\n",
        "\n",
        "pyg_dataset = Planetoid('./tmp', \"Cora\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzMatyCSUaB6"
      },
      "source": [
        "args = {\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'dropout': 0.5,\n",
        "    'num_layers': 2,\n",
        "    'hidden_size': 64,\n",
        "    'lr': 0.005,\n",
        "    'epochs': 150,\n",
        "}"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekV-sokSUeLc"
      },
      "source": [
        "## Partition the Graph into Clusters\n",
        "\n",
        "Here we use following three community detection / partition algorithms to partition the graph into different clusters:\n",
        "* [Kernighan–Lin algorithm (bisection)](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.kernighan_lin.kernighan_lin_bisection.html)\n",
        "* [Clauset-Newman-Moore greedy modularity maximization](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.modularity_max.greedy_modularity_communities.html#networkx.algorithms.community.modularity_max.greedy_modularity_communities)\n",
        "* [Louvain algorithm](https://python-louvain.readthedocs.io/en/latest/api.html)\n",
        "\n",
        "\n",
        "To make the training more stable, we discard the cluster that has less than 10 nodes.\n",
        "\n",
        "Let's first define these algorithms as DeepSNAP transformation on a graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8XeT005UcKh"
      },
      "source": [
        "def preprocess(G, node_label_index, method=\"louvain\"):\n",
        "    graphs = []\n",
        "    labeled_nodes = set(node_label_index.tolist())\n",
        "    if method == \"louvain\":\n",
        "        community_mapping = community_louvain.best_partition(G, resolution=10)\n",
        "        communities = {}\n",
        "        for node in community_mapping:\n",
        "            comm = community_mapping[node]\n",
        "            if comm in communities:\n",
        "                communities[comm].add(node)\n",
        "            else:\n",
        "                communities[comm] = set([node])\n",
        "        communities = communities.values()\n",
        "    elif method == \"bisection\":\n",
        "        communities = nx.algorithms.community.kernighan_lin_bisection(G)\n",
        "    elif method == \"greedy\":\n",
        "        communities = nx.algorithms.community.greedy_modularity_communities(G)\n",
        "\n",
        "    for community in communities:\n",
        "        nodes = set(community)\n",
        "        subgraph = G.subgraph(nodes)\n",
        "        # Make sure each subgraph has more than 10 nodes\n",
        "        if subgraph.number_of_nodes() > 10:\n",
        "            node_mapping = {node : i for i, node in enumerate(subgraph.nodes())}\n",
        "            subgraph = nx.relabel_nodes(subgraph, node_mapping)\n",
        "            # Get the id of the training set labeled node in the new graph\n",
        "            train_label_index = []\n",
        "            for node in labeled_nodes:\n",
        "                if node in node_mapping:\n",
        "                    # Append relabeled labeled node index\n",
        "                    train_label_index.append(node_mapping[node])\n",
        "\n",
        "            # Make sure the subgraph contains at least one training set labeled node\n",
        "            if len(train_label_index) > 0:\n",
        "                dg = Graph(subgraph)\n",
        "                # Update node_label_index\n",
        "                dg.node_label_index = torch.tensor(train_label_index, dtype=torch.long)\n",
        "                graphs.append(dg)\n",
        "    return graphs"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CYEamCAU-TJ"
      },
      "source": [
        "## Louvain Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TrC6ybWU7eO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "0c537f9f-ba1e-4559-dd0d-a2b00e08db74"
      },
      "source": [
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "graphs = preprocess(graph_train.G, graph_train.node_label_index, method=\"louvain\")\n",
        "print(\"Partition the graph in to {} communities\".format(len(graphs)))\n",
        "avg_num_nodes = 0\n",
        "avg_num_edges = 0\n",
        "for graph in graphs:\n",
        "    avg_num_nodes += graph.num_nodes\n",
        "    avg_num_edges += graph.num_edges\n",
        "avg_num_nodes = int(avg_num_nodes / len(graphs))\n",
        "avg_num_edges = int(avg_num_edges / len(graphs))\n",
        "print(\"Each community has {} nodes in average\".format(avg_num_nodes))\n",
        "print(\"Each community has {} edges in average\".format(avg_num_edges))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index fields: val_mask ignored.\n",
            "Index fields: test_mask ignored.\n",
            "Index fields: train_mask ignored.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-de32097bfaf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgraph_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgraph_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_label_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"louvain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Partition the graph in to {} communities\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mavg_num_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-871ae0854b2a>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(G, node_label_index, method)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabeled_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_label_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"louvain\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcommunity_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunity_louvain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcommunities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommunity_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'community' has no attribute 'best_partition'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03uXIuGVIgJ"
      },
      "source": [
        "## Louvain Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSbGf5ADVFQq"
      },
      "source": [
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "louvain_best_model, louvain_accs = train(graphs, [graph_train, graph_val, graph_test], args, model, optimizer, mode=\"community\")\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], louvain_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CvTf0ANVO9U"
      },
      "source": [
        "## Bisection Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkV0zlhgVJ7u"
      },
      "source": [
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "graphs = preprocess(graph_train.G, graph_train.node_label_index, method=\"bisection\")\n",
        "print(\"Partition the graph in to {} communities\".format(len(graphs)))\n",
        "avg_num_nodes = 0\n",
        "avg_num_edges = 0\n",
        "for graph in graphs:\n",
        "    avg_num_nodes += graph.num_nodes\n",
        "    avg_num_edges += graph.num_edges\n",
        "avg_num_nodes = int(avg_num_nodes / len(graphs))\n",
        "avg_num_edges = int(avg_num_edges / len(graphs))\n",
        "print(\"Each community has {} nodes in average\".format(avg_num_nodes))\n",
        "print(\"Each community has {} edges in average\".format(avg_num_edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqMCvP8wVVms"
      },
      "source": [
        "## Bisection Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1wgFg1bVRGY"
      },
      "source": [
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "bisection_best_model, bisection_accs = train(graphs, [graph_train, graph_val, graph_test], args, model, optimizer, mode=\"community\")\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], bisection_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PROPwoOVcJy"
      },
      "source": [
        "## Greedy Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3DVamWqVT92"
      },
      "source": [
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "graphs = preprocess(graph_train.G, graph_train.node_label_index, method=\"greedy\")\n",
        "print(\"Partition the graph in to {} communities\".format(len(graphs)))\n",
        "avg_num_nodes = 0\n",
        "avg_num_edges = 0\n",
        "for graph in graphs:\n",
        "    avg_num_nodes += graph.num_nodes\n",
        "    avg_num_edges += graph.num_edges\n",
        "avg_num_nodes = int(avg_num_nodes / len(graphs))\n",
        "avg_num_edges = int(avg_num_edges / len(graphs))\n",
        "print(\"Each community has {} nodes in average\".format(avg_num_nodes))\n",
        "print(\"Each community has {} edges in average\".format(avg_num_edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93pR_-kxVgma"
      },
      "source": [
        "## Greedy Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQgQY-jPVd_U"
      },
      "source": [
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "greedy_best_model, greedy_accs = train(graphs, [graph_train, graph_val, graph_test], args, model, optimizer, mode=\"community\")\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], greedy_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5edKKT6Vk1C"
      },
      "source": [
        "## Full-Batch Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5tIXxC8ViFD"
      },
      "source": [
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, verbose=True, fixed_split=True)\n",
        "\n",
        "graph_train = graphs_train[0]\n",
        "graph_val = graphs_val[0]\n",
        "graph_test = graphs_test[0]\n",
        "\n",
        "model = GNN(graph_train.num_node_features, args['hidden_size'], graph_train.num_node_labels, args).to(args['device'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "graphs = [graph_train, graph_val, graph_test]\n",
        "all_best_model, all_accs = train(graphs, graphs, args, model, optimizer, mode=\"all\")\n",
        "train_acc, val_acc, test_acc = test([graph_train, graph_val, graph_test], all_best_model)\n",
        "print('Best model:',\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * val_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RpuETv7Vpx0"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMK33kY5VmF5"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "louvain_results = np.array(louvain_accs)\n",
        "bisection_results = np.array(bisection_accs)\n",
        "greedy_results = np.array(greedy_accs)\n",
        "all_results = np.array(all_accs)\n",
        "\n",
        "x = np.arange(1, 151)\n",
        "\n",
        "plt.figure(figsize=(9, 7))\n",
        "\n",
        "plt.plot(x, louvain_results[:, 1], label=\"Louvain Validation\")\n",
        "plt.plot(x, louvain_results[:, 2], label=\"Louvain Test\")\n",
        "plt.plot(x, bisection_results[:, 1], label=\"Bisection Validation\")\n",
        "plt.plot(x, bisection_results[:, 2], label=\"Bisection Test\")\n",
        "plt.plot(x, greedy_results[:, 1], label=\"Greedy Validation\")\n",
        "plt.plot(x, greedy_results[:, 2], label=\"Greedy Test\")\n",
        "plt.plot(x, all_results[:, 1], label=\"All Validation\")\n",
        "plt.plot(x, all_results[:, 2], label=\"All Test\")\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}